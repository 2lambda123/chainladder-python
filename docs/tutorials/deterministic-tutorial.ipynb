{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Deterministic Methods\n",
    "### Getting Started\n",
    "This tutorial focuses on using deterministic methods to square a triangle. \n",
    "\n",
    "Note that a lot of the examples shown here might not be applicable in a real world scenario, and is only meant to demonstrate some of the functionalities included in the package. The user should always exercise their best actuarial judgement, and follow any applicable laws, the Code of Professional Conduct, and applicable Actuarial Standards of Practice.\n",
    "\n",
    "Be sure to make sure your packages are updated. For more info on how to update your pakages, visit [Keeping Packages Updated](https://chainladder-python.readthedocs.io/en/latest/install.html#keeping-packages-updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.3.1\n",
      "numpy: 1.20.3\n",
      "chainladder: 0.8.6\n"
     ]
    }
   ],
   "source": [
    "# Black linter, optional\n",
    "%load_ext lab_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chainladder as cl\n",
    "import os\n",
    "\n",
    "print(\"pandas: \" + pd.__version__)\n",
    "print(\"numpy: \" + np.__version__)\n",
    "print(\"chainladder: \" + cl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chainladder Method\n",
    "\n",
    "The basic chainladder method is entirely specified by its development pattern selections.  For this reason, the `Chainladder` estimator takes no additional assumptions, i.e. no additional arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chainladder()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.Chainladder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating an Triangle with `Development` patterns and a `TailCurve`.  Recall, we can bundle these two estimators into a single `Pipeline` if we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "genins = cl.load_sample(\"genins\")\n",
    "\n",
    "genins_dev = cl.Pipeline(\n",
    "    [(\"dev\", cl.Development()), (\"tail\", cl.TailCurve())]\n",
    ").fit_transform(genins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the basic `Chainladder` estimator to estimate `ultimate_` values of our `Triangle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>4,016,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>5,594,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>5,537,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>5,454,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>5,001,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>5,261,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>5,827,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>6,984,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>5,808,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>5,116,430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "              2261\n",
       "2001  4.016553e+06\n",
       "2002  5.594009e+06\n",
       "2003  5.537497e+06\n",
       "2004  5.454190e+06\n",
       "2005  5.001513e+06\n",
       "2006  5.261947e+06\n",
       "2007  5.827759e+06\n",
       "2008  6.984945e+06\n",
       "2009  5.808708e+06\n",
       "2010  5.116430e+06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model = cl.Chainladder().fit(genins_dev)\n",
    "genins_model.ultimate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the `ibnr_`.  Techincally the term IBNR is reserved for incurred but not reported, but the `chainladder` models use it to generally describe to amounts out of the lower half of the triangle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>115,090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>254,924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>628,182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>865,922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1,128,202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>1,570,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2,344,629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>4,120,447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>4,445,414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>4,772,416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "              2261\n",
       "2001  1.150899e+05\n",
       "2002  2.549240e+05\n",
       "2003  6.281822e+05\n",
       "2004  8.659217e+05\n",
       "2005  1.128202e+06\n",
       "2006  1.570235e+06\n",
       "2007  2.344629e+06\n",
       "2008  4.120447e+06\n",
       "2009  4.445414e+06\n",
       "2010  4.772416e+06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.ibnr_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to see the completed `Triangle` and this can be accomplished by inspecting the `full_triangle_`.  As with most other estimator properties, the `full_triangle_` is itself a `Triangle` and can be manipulated as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>357,848</td>\n",
       "      <td>766,940</td>\n",
       "      <td>610,542</td>\n",
       "      <td>482,940</td>\n",
       "      <td>527,326</td>\n",
       "      <td>574,398</td>\n",
       "      <td>146,342</td>\n",
       "      <td>139,950</td>\n",
       "      <td>227,229</td>\n",
       "      <td>67,948</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>68,482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td></td>\n",
       "      <td>352,118</td>\n",
       "      <td>884,021</td>\n",
       "      <td>933,894</td>\n",
       "      <td>1,183,289</td>\n",
       "      <td>445,745</td>\n",
       "      <td>320,996</td>\n",
       "      <td>527,804</td>\n",
       "      <td>266,172</td>\n",
       "      <td>425,046</td>\n",
       "      <td>...</td>\n",
       "      <td>64,913</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>95,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>290,507</td>\n",
       "      <td>1,001,799</td>\n",
       "      <td>926,219</td>\n",
       "      <td>1,016,654</td>\n",
       "      <td>750,816</td>\n",
       "      <td>146,923</td>\n",
       "      <td>495,992</td>\n",
       "      <td>280,405</td>\n",
       "      <td>...</td>\n",
       "      <td>93,678</td>\n",
       "      <td>64,257</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>94,413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>310,608</td>\n",
       "      <td>1,108,250</td>\n",
       "      <td>776,189</td>\n",
       "      <td>1,562,400</td>\n",
       "      <td>272,482</td>\n",
       "      <td>352,053</td>\n",
       "      <td>206,286</td>\n",
       "      <td>...</td>\n",
       "      <td>370,179</td>\n",
       "      <td>92,268</td>\n",
       "      <td>63,291</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>92,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>443,160</td>\n",
       "      <td>693,190</td>\n",
       "      <td>991,983</td>\n",
       "      <td>769,488</td>\n",
       "      <td>504,851</td>\n",
       "      <td>470,639</td>\n",
       "      <td>...</td>\n",
       "      <td>226,674</td>\n",
       "      <td>339,456</td>\n",
       "      <td>84,611</td>\n",
       "      <td>58,038</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>85,275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>396,132</td>\n",
       "      <td>937,085</td>\n",
       "      <td>847,498</td>\n",
       "      <td>805,037</td>\n",
       "      <td>705,960</td>\n",
       "      <td>...</td>\n",
       "      <td>351,548</td>\n",
       "      <td>238,477</td>\n",
       "      <td>357,132</td>\n",
       "      <td>89,016</td>\n",
       "      <td>61,060</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>89,715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>440,832</td>\n",
       "      <td>847,631</td>\n",
       "      <td>1,131,398</td>\n",
       "      <td>1,063,269</td>\n",
       "      <td>...</td>\n",
       "      <td>424,501</td>\n",
       "      <td>389,349</td>\n",
       "      <td>264,121</td>\n",
       "      <td>395,534</td>\n",
       "      <td>98,588</td>\n",
       "      <td>67,626</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99,362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>359,480</td>\n",
       "      <td>1,061,648</td>\n",
       "      <td>1,443,370</td>\n",
       "      <td>...</td>\n",
       "      <td>725,788</td>\n",
       "      <td>508,792</td>\n",
       "      <td>466,660</td>\n",
       "      <td>316,566</td>\n",
       "      <td>474,073</td>\n",
       "      <td>118,164</td>\n",
       "      <td>81,054</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>119,092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>376,686</td>\n",
       "      <td>986,608</td>\n",
       "      <td>...</td>\n",
       "      <td>1,089,616</td>\n",
       "      <td>603,569</td>\n",
       "      <td>423,113</td>\n",
       "      <td>388,076</td>\n",
       "      <td>263,257</td>\n",
       "      <td>394,241</td>\n",
       "      <td>98,266</td>\n",
       "      <td>67,405</td>\n",
       "      <td></td>\n",
       "      <td>99,038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>344,014</td>\n",
       "      <td>...</td>\n",
       "      <td>897,410</td>\n",
       "      <td>959,756</td>\n",
       "      <td>531,636</td>\n",
       "      <td>372,687</td>\n",
       "      <td>341,826</td>\n",
       "      <td>231,882</td>\n",
       "      <td>347,255</td>\n",
       "      <td>86,555</td>\n",
       "      <td>59,371</td>\n",
       "      <td>87,234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          2001      2002      2003       2004       2005       2006       2007      2008       2009       2010          2011          2012           2013           2014           2015           2016           2017           2018          2019          2020           2261\n",
       "2001  357848.0  766940.0  610542.0   482940.0   527326.0   574398.0   146342.0  139950.0   227229.0    67948.0  4.660832e+04           NaN            NaN            NaN            NaN            NaN            NaN            NaN           NaN           NaN   68481.607479\n",
       "2002       NaN  352118.0  884021.0   933894.0  1183289.0   445745.0   320996.0  527804.0   266172.0   425046.0  9.463381e+04  6.491321e+04            NaN            NaN            NaN            NaN            NaN            NaN           NaN           NaN   95376.990378\n",
       "2003       NaN       NaN  290507.0  1001799.0   926219.0  1016654.0   750816.0  146923.0   495992.0   280405.0  3.758335e+05  9.367780e+04   64257.444029            NaN            NaN            NaN            NaN            NaN           NaN           NaN   94413.472765\n",
       "2004       NaN       NaN       NaN   310608.0  1108250.0   776189.0  1562400.0  272482.0   352053.0   206286.0  2.471900e+05  3.701793e+05   92268.491259   63290.738238            NaN            NaN            NaN            NaN           NaN           NaN   92993.091793\n",
       "2005       NaN       NaN       NaN        NaN   443160.0   693190.0   991983.0  769488.0   504851.0   470639.0  3.341481e+05  2.266741e+05  339455.859834   84610.554829   58037.845908            NaN            NaN            NaN           NaN           NaN   85275.016254\n",
       "2006       NaN       NaN       NaN        NaN        NaN   396132.0   937085.0  847498.0   805037.0   705960.0  3.832866e+05  3.515475e+05  238477.319189  357131.701211   89016.319828   61059.940618            NaN            NaN           NaN           NaN   89715.380493\n",
       "2007       NaN       NaN       NaN        NaN        NaN        NaN   440832.0  847631.0  1131398.0  1063269.0  6.055481e+05  4.245010e+05  389349.093199  264120.547162  395533.716386   98588.155801   67625.655054            NaN           NaN           NaN   99362.385761\n",
       "2008       NaN       NaN       NaN        NaN        NaN        NaN        NaN  359480.0  1061648.0  1443370.0  1.310258e+06  7.257885e+05  508791.855239  466660.022126  316565.525733  474072.692256  118164.268959   81053.713068           NaN           NaN  119092.233545\n",
       "2009       NaN       NaN       NaN        NaN        NaN        NaN        NaN       NaN   376686.0   986608.0  1.018834e+06  1.089616e+06  603568.642933  423113.361911  388076.359317  263257.169860  394240.765738   98265.883351  67404.595177           NaN   99037.582449\n",
       "2010       NaN       NaN       NaN        NaN        NaN        NaN        NaN       NaN        NaN   344014.0  8.568035e+05  8.974101e+05  959756.260737  531635.730480  372686.990732  341825.674980  231882.354130  347255.411513  86554.620238  59371.360017   87234.348747"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_triangle_.dev_to_val().cum_to_incr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the calendar year of our ultimates.  While ultimates will generally be realized before this date, the `chainladder` package picks the highest allowable date available for its `ultimate_` valuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2261-12-31 23:59:59.999999999')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_triangle_.valuation_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful property is the `full_expectation_`.  Like the `full_triangle`, it \"squares\" the `Triangle`, but replaces the known data with the expected implied by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "      <th>120</th>\n",
       "      <th>132</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>270,061</td>\n",
       "      <td>942,678</td>\n",
       "      <td>1,647,172</td>\n",
       "      <td>2,400,610</td>\n",
       "      <td>2,817,960</td>\n",
       "      <td>3,110,531</td>\n",
       "      <td>3,378,874</td>\n",
       "      <td>3,560,909</td>\n",
       "      <td>3,833,515</td>\n",
       "      <td>3,901,463</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>4,016,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>376,125</td>\n",
       "      <td>1,312,904</td>\n",
       "      <td>2,294,081</td>\n",
       "      <td>3,343,423</td>\n",
       "      <td>3,924,682</td>\n",
       "      <td>4,332,157</td>\n",
       "      <td>4,705,889</td>\n",
       "      <td>4,959,416</td>\n",
       "      <td>5,339,085</td>\n",
       "      <td>5,433,719</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,594,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>372,325</td>\n",
       "      <td>1,299,641</td>\n",
       "      <td>2,270,905</td>\n",
       "      <td>3,309,647</td>\n",
       "      <td>3,885,035</td>\n",
       "      <td>4,288,393</td>\n",
       "      <td>4,658,349</td>\n",
       "      <td>4,909,315</td>\n",
       "      <td>5,285,148</td>\n",
       "      <td>5,378,826</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,537,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>366,724</td>\n",
       "      <td>1,280,089</td>\n",
       "      <td>2,236,741</td>\n",
       "      <td>3,259,856</td>\n",
       "      <td>3,826,587</td>\n",
       "      <td>4,223,877</td>\n",
       "      <td>4,588,268</td>\n",
       "      <td>4,835,458</td>\n",
       "      <td>5,205,637</td>\n",
       "      <td>5,297,906</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,454,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>336,287</td>\n",
       "      <td>1,173,846</td>\n",
       "      <td>2,051,100</td>\n",
       "      <td>2,989,300</td>\n",
       "      <td>3,508,995</td>\n",
       "      <td>3,873,311</td>\n",
       "      <td>4,207,459</td>\n",
       "      <td>4,434,133</td>\n",
       "      <td>4,773,589</td>\n",
       "      <td>4,858,200</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>5,001,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>353,798</td>\n",
       "      <td>1,234,970</td>\n",
       "      <td>2,157,903</td>\n",
       "      <td>3,144,956</td>\n",
       "      <td>3,691,712</td>\n",
       "      <td>4,074,999</td>\n",
       "      <td>4,426,546</td>\n",
       "      <td>4,665,023</td>\n",
       "      <td>5,022,155</td>\n",
       "      <td>5,111,171</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,261,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>391,842</td>\n",
       "      <td>1,367,765</td>\n",
       "      <td>2,389,941</td>\n",
       "      <td>3,483,130</td>\n",
       "      <td>4,088,678</td>\n",
       "      <td>4,513,179</td>\n",
       "      <td>4,902,528</td>\n",
       "      <td>5,166,649</td>\n",
       "      <td>5,562,182</td>\n",
       "      <td>5,660,771</td>\n",
       "      <td>5,728,396</td>\n",
       "      <td>5,827,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>469,648</td>\n",
       "      <td>1,639,355</td>\n",
       "      <td>2,864,498</td>\n",
       "      <td>4,174,756</td>\n",
       "      <td>4,900,545</td>\n",
       "      <td>5,409,337</td>\n",
       "      <td>5,875,997</td>\n",
       "      <td>6,192,562</td>\n",
       "      <td>6,666,635</td>\n",
       "      <td>6,784,799</td>\n",
       "      <td>6,865,853</td>\n",
       "      <td>6,984,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>390,561</td>\n",
       "      <td>1,363,294</td>\n",
       "      <td>2,382,128</td>\n",
       "      <td>3,471,744</td>\n",
       "      <td>4,075,313</td>\n",
       "      <td>4,498,426</td>\n",
       "      <td>4,886,502</td>\n",
       "      <td>5,149,760</td>\n",
       "      <td>5,544,000</td>\n",
       "      <td>5,642,266</td>\n",
       "      <td>5,709,671</td>\n",
       "      <td>5,808,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>344,014</td>\n",
       "      <td>1,200,818</td>\n",
       "      <td>2,098,228</td>\n",
       "      <td>3,057,984</td>\n",
       "      <td>3,589,620</td>\n",
       "      <td>3,962,307</td>\n",
       "      <td>4,304,132</td>\n",
       "      <td>4,536,015</td>\n",
       "      <td>4,883,270</td>\n",
       "      <td>4,969,825</td>\n",
       "      <td>5,029,196</td>\n",
       "      <td>5,116,430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "               12            24            36            48            60            72            84            96            108           120           132           9999\n",
       "2001  270061.415645  9.426781e+05  1.647172e+06  2.400610e+06  2.817960e+06  3.110531e+06  3.378874e+06  3.560909e+06  3.833515e+06  3.901463e+06  3.948071e+06  4.016553e+06\n",
       "2002  376125.006253  1.312904e+06  2.294081e+06  3.343423e+06  3.924682e+06  4.332157e+06  4.705889e+06  4.959416e+06  5.339085e+06  5.433719e+06  5.498632e+06  5.594009e+06\n",
       "2003  372325.315504  1.299641e+06  2.270905e+06  3.309647e+06  3.885035e+06  4.288393e+06  4.658349e+06  4.909315e+06  5.285148e+06  5.378826e+06  5.443084e+06  5.537497e+06\n",
       "2004  366723.956096  1.280089e+06  2.236741e+06  3.259856e+06  3.826587e+06  4.223877e+06  4.588268e+06  4.835458e+06  5.205637e+06  5.297906e+06  5.361197e+06  5.454190e+06\n",
       "2005  336287.252245  1.173846e+06  2.051100e+06  2.989300e+06  3.508995e+06  3.873311e+06  4.207459e+06  4.434133e+06  4.773589e+06  4.858200e+06  4.916237e+06  5.001513e+06\n",
       "2006  353798.100727  1.234970e+06  2.157903e+06  3.144956e+06  3.691712e+06  4.074999e+06  4.426546e+06  4.665023e+06  5.022155e+06  5.111171e+06  5.172231e+06  5.261947e+06\n",
       "2007  391841.657172  1.367765e+06  2.389941e+06  3.483130e+06  4.088678e+06  4.513179e+06  4.902528e+06  5.166649e+06  5.562182e+06  5.660771e+06  5.728396e+06  5.827759e+06\n",
       "2008  469647.520951  1.639355e+06  2.864498e+06  4.174756e+06  4.900545e+06  5.409337e+06  5.875997e+06  6.192562e+06  6.666635e+06  6.784799e+06  6.865853e+06  6.984945e+06\n",
       "2009  390560.775407  1.363294e+06  2.382128e+06  3.471744e+06  4.075313e+06  4.498426e+06  4.886502e+06  5.149760e+06  5.544000e+06  5.642266e+06  5.709671e+06  5.808708e+06\n",
       "2010  344014.000000  1.200818e+06  2.098228e+06  3.057984e+06  3.589620e+06  3.962307e+06  4.304132e+06  4.536015e+06  4.883270e+06  4.969825e+06  5.029196e+06  5.116430e+06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_expectation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some clever arithmetic, we can use these objects to give us other useful information.  For example, we can retrospectively review the actual `Triangle` against its modeled expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "      <th>120</th>\n",
       "      <th>132</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>87,787</td>\n",
       "      <td>182,110</td>\n",
       "      <td>88,158</td>\n",
       "      <td>-182,340</td>\n",
       "      <td>-72,364</td>\n",
       "      <td>209,463</td>\n",
       "      <td>87,462</td>\n",
       "      <td>45,377</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>-24,007</td>\n",
       "      <td>-76,765</td>\n",
       "      <td>-124,048</td>\n",
       "      <td>9,899</td>\n",
       "      <td>-125,615</td>\n",
       "      <td>-212,094</td>\n",
       "      <td>-58,022</td>\n",
       "      <td>-45,377</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-81,818</td>\n",
       "      <td>-7,335</td>\n",
       "      <td>-52,380</td>\n",
       "      <td>-74,468</td>\n",
       "      <td>100,960</td>\n",
       "      <td>-155,475</td>\n",
       "      <td>-29,439</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-56,116</td>\n",
       "      <td>138,769</td>\n",
       "      <td>-41,694</td>\n",
       "      <td>497,591</td>\n",
       "      <td>203,342</td>\n",
       "      <td>158,105</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>106,873</td>\n",
       "      <td>-37,496</td>\n",
       "      <td>77,233</td>\n",
       "      <td>-91,479</td>\n",
       "      <td>-106,323</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>42,334</td>\n",
       "      <td>98,247</td>\n",
       "      <td>22,812</td>\n",
       "      <td>-159,204</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>48,990</td>\n",
       "      <td>-79,302</td>\n",
       "      <td>29,920</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-110,168</td>\n",
       "      <td>-218,227</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-13,875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "               12            24            36            48            60            72            84            96            108           120           132           9999\n",
       "2001   87786.584355  1.821099e+05  8.815770e+04 -1.823400e+05 -7.236421e+04  2.094632e+05  8.746170e+04  4.537702e+04  4.656613e-10           NaN           NaN           NaN\n",
       "2002  -24007.006253 -7.676541e+04 -1.240477e+05  9.899296e+03 -1.256155e+05 -2.120939e+05 -5.802227e+04 -4.537702e+04           NaN           NaN           NaN           NaN\n",
       "2003  -81818.315504 -7.335184e+03 -5.238046e+04 -7.446777e+04  1.009605e+05 -1.554745e+05 -2.943943e+04           NaN -9.313226e-10 -9.313226e-10           NaN           NaN\n",
       "2004  -56115.956096  1.387690e+05 -4.169437e+04  4.975914e+05  2.033420e+05  1.581052e+05           NaN           NaN -9.313226e-10 -9.313226e-10 -9.313226e-10 -9.313226e-10\n",
       "2005  106872.747755 -3.749648e+04  7.723272e+04 -9.147888e+04 -1.063228e+05           NaN           NaN           NaN -9.313226e-10           NaN -9.313226e-10 -9.313226e-10\n",
       "2006   42333.899273  9.824703e+04  2.281166e+04 -1.592040e+05           NaN -4.656613e-10 -9.313226e-10 -9.313226e-10 -9.313226e-10 -1.862645e-09 -1.862645e-09 -1.862645e-09\n",
       "2007   48990.342828 -7.930205e+04  2.992047e+04           NaN           NaN           NaN -9.313226e-10 -9.313226e-10           NaN -2.793968e-09 -1.862645e-09 -1.862645e-09\n",
       "2008 -110167.520951 -2.182267e+05           NaN           NaN           NaN           NaN -9.313226e-10 -1.862645e-09 -1.862645e-09 -1.862645e-09 -2.793968e-09 -1.862645e-09\n",
       "2009  -13874.775407           NaN           NaN  4.656613e-10           NaN -9.313226e-10           NaN -9.313226e-10 -1.862645e-09           NaN -9.313226e-10           NaN\n",
       "2010            NaN -2.328306e-10 -4.656613e-10 -9.313226e-10 -2.328306e-09  4.656613e-10 -2.793968e-09  1.862645e-09  1.862645e-09  2.793968e-09 -1.862645e-09  3.725290e-09"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(genins_model.full_triangle_ - genins_model.full_expectation_).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting comfortable with manipulating `Triangle`s will greatly improve your ability to extract value out of the `chainladder` package.  Here is another way of getting the same answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>87,787</td>\n",
       "      <td>182,110</td>\n",
       "      <td>88,158</td>\n",
       "      <td>-182,340</td>\n",
       "      <td>-72,364</td>\n",
       "      <td>209,463</td>\n",
       "      <td>87,462</td>\n",
       "      <td>45,377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>-24,007</td>\n",
       "      <td>-76,765</td>\n",
       "      <td>-124,048</td>\n",
       "      <td>9,899</td>\n",
       "      <td>-125,615</td>\n",
       "      <td>-212,094</td>\n",
       "      <td>-58,022</td>\n",
       "      <td>-45,377</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-81,818</td>\n",
       "      <td>-7,335</td>\n",
       "      <td>-52,380</td>\n",
       "      <td>-74,468</td>\n",
       "      <td>100,960</td>\n",
       "      <td>-155,475</td>\n",
       "      <td>-29,439</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-56,116</td>\n",
       "      <td>138,769</td>\n",
       "      <td>-41,694</td>\n",
       "      <td>497,591</td>\n",
       "      <td>203,342</td>\n",
       "      <td>158,105</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>106,873</td>\n",
       "      <td>-37,496</td>\n",
       "      <td>77,233</td>\n",
       "      <td>-91,479</td>\n",
       "      <td>-106,323</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>42,334</td>\n",
       "      <td>98,247</td>\n",
       "      <td>22,812</td>\n",
       "      <td>-159,204</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>48,990</td>\n",
       "      <td>-79,302</td>\n",
       "      <td>29,920</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-110,168</td>\n",
       "      <td>-218,227</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-13,875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                12             24             36             48             60             72            84            96            108\n",
       "2001   87786.584355  182109.854207   88157.704861 -182340.046069  -72364.206180  209463.211490  87461.697305  45377.021916  4.656613e-10\n",
       "2002  -24007.006253  -76765.409669 -124047.730972    9899.295819 -125615.456548 -212093.852125 -58022.270396 -45377.021916           NaN\n",
       "2003  -81818.315504   -7335.184258  -52380.464273  -74467.773015  100960.477986 -155474.528980 -29439.426909           NaN           NaN\n",
       "2004  -56115.956096  138768.957566  -41694.368640  497591.418491  203341.953249  158105.169615           NaN           NaN           NaN\n",
       "2005  106872.747755  -37496.484673   77232.720516  -91478.875281 -106322.768507            NaN           NaN           NaN           NaN\n",
       "2006   42333.899273   98247.032955   22811.664568 -159204.019945            NaN            NaN           NaN           NaN           NaN\n",
       "2007   48990.342828  -79302.054276   29920.473940            NaN            NaN            NaN           NaN           NaN           NaN\n",
       "2008 -110167.520951 -218226.711852            NaN            NaN            NaN            NaN           NaN           NaN           NaN\n",
       "2009  -13874.775407            NaN            NaN            NaN            NaN            NaN           NaN           NaN           NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = genins - genins_model.full_expectation_\n",
    "out[out.valuation <= genins.valuation_date].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the IBNR expected to runoff in the up coming year..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>46,608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>94,634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>375,833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>247,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>334,148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>383,287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>605,548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1,310,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1,018,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>856,804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "              2011\n",
       "2001  4.660832e+04\n",
       "2002  9.463381e+04\n",
       "2003  3.758335e+05\n",
       "2004  2.471900e+05\n",
       "2005  3.341481e+05\n",
       "2006  3.832866e+05\n",
       "2007  6.055481e+05\n",
       "2008  1.310258e+06\n",
       "2009  1.018834e+06\n",
       "2010  8.568035e+05"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_yr_ibnr = genins_model.full_triangle_.dev_to_val().cum_to_incr()\n",
    "cal_yr_ibnr[cal_yr_ibnr.valuation.year == 2011]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The BornhuetterFerguson method\n",
    "The `BornhuetterFerguson` estimator is another deterministic method having many of the same attributes as the `Chainladder` estimator.  It comes with one assumption, the `apriori`.  This is a scalar multiplier that is to be applied to an exposure vector to determine an apriori ultimate estimate of our model.\n",
    "\n",
    "Since the CAS Loss Reserve Database has premium, we will use it as an example.  Let's grab the paid loss and net earned premium  for the commercial auto line of business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Triangle Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Valuation:</th>\n",
       "      <td>1997-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grain:</th>\n",
       "      <td>OYDY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shape:</th>\n",
       "      <td>(1, 2, 10, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index:</th>\n",
       "      <td>[LOB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columns:</th>\n",
       "      <td>[CumPaidLoss, EarnedPremNet]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                        Triangle Summary\n",
       "Valuation:                       1997-12\n",
       "Grain:                              OYDY\n",
       "Shape:                    (1, 2, 10, 10)\n",
       "Index:                             [LOB]\n",
       "Columns:    [CumPaidLoss, EarnedPremNet]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comauto = (\n",
    "    cl.load_sample(\"clrd\")\n",
    "    .groupby(\"LOB\")\n",
    "    .sum()\n",
    "    .loc[\"comauto\"][[\"CumPaidLoss\", \"EarnedPremNet\"]]\n",
    ")\n",
    "comauto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set an apriori Loss Ratio estimate of 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_model = cl.BornhuetterFerguson(apriori=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BornhuetterFerguson` method along with all other expected loss methods like `CapeCod` and `Benktander`, need to take in an exposure vector.  The exposure vector has to be a `Triangle` itself. The `Triangle` class supports single exposure vectors and you can learn more about it in our previous [Triangle tutorial](https://chainladder-python.readthedocs.io/en/latest/tutorials/triangle-tutorial.html#Initializing-a-triangle-with-your-own-data).\n",
    "\n",
    "The signature for the `fit` function for all estmators is:\n",
    "```python\n",
    "estimator.fit(X, y=None, sample_weight)\n",
    "```\n",
    "This signature comes from `sklearn` and while we don't use y, the `sample_weight` is used to include an exposure vector for our `BornhuetterFerguson` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BornhuetterFerguson(apriori=0.75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_model.fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an `apriori` that takes on only a constant for all origins can be limiting.  This shouldn't stop the practitioner from exploiting the fact that the `apriori` can be embedded directly in the exposure vector itself allowing full cusomization of the `apriori`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = cl.BornhuetterFerguson(apriori=0.75).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "\n",
    "b2 = cl.BornhuetterFerguson(apriori=1.0).fit(\n",
    "    X=comauto[\"CumPaidLoss\"],\n",
    "    sample_weight=0.75 * comauto[\"EarnedPremNet\"].latest_diagonal,\n",
    ")\n",
    "\n",
    "b1.ultimate_ == b2.ultimate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the results of our `BornhuetterFerguson` model to our `Chainladder` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_model = cl.Chainladder().fit(comauto[\"CumPaidLoss\"])\n",
    "bf_model.ultimate_.to_frame().merge(\n",
    "    cl_model.ultimate_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"BF\", \"CL\"),\n",
    ").plot(title=\"BF vs CL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Benktander method\n",
    "The Benktander method is similar to the `BornhuetterFerguson` method, but allows the specification of one additional assumption, `n_iters`.  The Benktander method generalizes both the `BornhuetterFerguson` and the `Chainladder` estimator through this assumption.\n",
    "\n",
    "* where `n_iters=1` we get the `BornhuetterFerguson` estimator<br>\n",
    "* where `n_iters` is sufficiently large, we converge to the `Chainladder` estimator.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_model = cl.Benktander(apriori=0.75, n_iters=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the `Bentander` method looks identical to the `BornhuetterFerguson` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benktander(apriori=0.75, n_iters=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_model.fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once fit, it has the usual properties we would expect - `ultimate_`, `ibnr_`, `full_triangle_`, and `full_expectation_`.  Let's re-use our same `Chainladder` comparison with the `Benktander` model.  Notice that even at `n_iters=3` it already approximates the `Chainladder` far better than the `BornhuetterFerguson` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_model.ultimate_.to_frame().merge(\n",
    "    cl_model.ultimate_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"BF\", \"CL\"),\n",
    ").plot(title=\"BF vs CL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cape Cod method\n",
    "`CapeCod` is similar to the `BornhuetterFerguson` method except its `apriori` is computed from the `Triangle` itself.  Instead of specifying an `apriori`, you instead specify a `decay` and a `trend`.  \n",
    "\n",
    "* `decay` is a rate that gives weight to earlier acident periods \n",
    "* `trend` is a trend rate along the `origin` axis to reflect possible systematic inflationary impacts on the apriori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_model = cl.CapeCod(decay=1, trend=0).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you `fit` a `CapeCod`, you can see the `apriori` it computes given the `decay` and `trend` assumptions.  Since it is an estimated parameter, the `CapeCod` attribute is called the `apriori_` with a trailing underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          2261\n",
       "1988  0.685686\n",
       "1989  0.685686\n",
       "1990  0.685686\n",
       "1991  0.685686\n",
       "1992  0.685686\n",
       "1993  0.685686\n",
       "1994  0.685686\n",
       "1995  0.685686\n",
       "1996  0.685686\n",
       "1997  0.685686"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_model.apriori_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a `decay=1`, each `origin` period gets the same `apriori_`.  Let's verify that this `apriori_` makes sense.  It should be the latest incurred losses over the 'used up premium' where 'used up premium' is the premium vector / CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6856862224535671"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_diagonal = comauto[\"CumPaidLoss\"].latest_diagonal\n",
    "\n",
    "cdf_as_origin_vector = (\n",
    "    cl.Chainladder().fit(comauto[\"CumPaidLoss\"]).ultimate_\n",
    "    / comauto[\"CumPaidLoss\"].latest_diagonal\n",
    ")\n",
    "\n",
    "used_up_premium = comauto[\"EarnedPremNet\"].latest_diagonal / cdf_as_origin_vector\n",
    "\n",
    "apriori_check = latest_diagonal.sum() / used_up_premium.sum()\n",
    "apriori_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a `decay=0`, the `apriori_` for each `origin` period stands on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.6853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.6478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.6518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.6815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          2261\n",
       "1988  0.685281\n",
       "1989  0.704094\n",
       "1990  0.690279\n",
       "1991  0.647802\n",
       "1992  0.651835\n",
       "1993  0.681518\n",
       "1994  0.692516\n",
       "1995  0.700403\n",
       "1996  0.703893\n",
       "1997  0.761919"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_model = cl.CapeCod(decay=0, trend=0).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "cc_model.apriori_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same on our manually calculated `apriori_` yields the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1997</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.6853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.6478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.6518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.6815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          1997\n",
       "1988  0.685281\n",
       "1989  0.704094\n",
       "1990  0.690279\n",
       "1991  0.647802\n",
       "1992  0.651835\n",
       "1993  0.681518\n",
       "1994  0.692516\n",
       "1995  0.700403\n",
       "1996  0.703893\n",
       "1997  0.761919"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_diagonal / used_up_premium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine our `apriori_` for whether it exhibits any trending over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_model.apriori_.plot(title=\"Apriori by Accident Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much trend, but lets judgementally flatten it by modifying our `trend` assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trended_cc_model = cl.CapeCod(decay=0, trend=0.01).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "\n",
    "cc_model.apriori_.to_frame().merge(\n",
    "    trended_cc_model.apriori_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"_original\", \"_trended\"),\n",
    ").plot(title=\"Original vs Trended Apriori\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding `trend` to the `CapeCod` method is intended to adjust `apriori_`s to a common level.  Once at a common level, the `apriori_` can be estimated from multiple `origin` periods using the `decay` factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trended_cc_model = cl.CapeCod(decay=0.75, trend=0.01).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "\n",
    "cc_model.apriori_.to_frame().merge(\n",
    "    trended_cc_model.apriori_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"_untrended\", \"_trended\"),\n",
    ").plot(title=\"Original vs Trended and Blended Apriori\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once estimated, it is necessary to detrend our `apriori_`s back to their untrended levels and these are contained in `detrended_apriori_`. It is the `detrended_apriori_` that gets used in the calculation of `ultimate_` losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_model.apriori_.to_frame().merge(\n",
    "    trended_cc_model.detrended_apriori_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"_original\", \"_smoothed\"),\n",
    ").plot(title=\"Original vs Blended Apriori\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `detrended_apriori_` is a much smoother estimate of the initial expected `ultimate_`.  With the `detrended_apriori_` in hand, the `CapeCod` method estimator behaves exactly like our the `BornhuetterFerguson` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF vs CC Difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "bf = cl.BornhuetterFerguson().fit(\n",
    "    X=comauto[\"CumPaidLoss\"],\n",
    "    sample_weight=trended_cc_model.detrended_apriori_\n",
    "    * comauto[\"EarnedPremNet\"].latest_diagonal,\n",
    ")\n",
    "print(\"BF vs CC Difference: \", bf.ultimate_.sum() - trended_cc_model.ultimate_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the `CapeCod ultimate_` to the basic `Chainladder` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trended_cc_model.ultimate_.to_frame().merge(\n",
    "    cl_model.ultimate_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"CC\", \"CL\"),\n",
    ").plot(title=\"CC vs CL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "* All the deterministic estimators have `ultimate_`, `ibnr_`, `full_expecation_` and `full_triangle_` attributes that are themselves `Triangle`s.  These can be manipulated in a variety of ways to gain additional insights from your model.<br>\n",
    "* The expected loss methods take in an exposure vector which itself is a `Triangle` through the `sample_weight` argument of the `fit` method.<br>\n",
    "* The `CapeCod` method has the additional attributes `apriori_` and `detrended_apriori_` to accomodate the selection of its `trend` and `decay` assumptions.\n",
    "\n",
    "Finally, these esimators work very well with the transformers discussed in previous tutorials.  Let's go to town demonstating the compositional nature of these estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "wkcomp = (\n",
    "    cl.load_sample(\"clrd\")\n",
    "    .groupby(\"LOB\")\n",
    "    .sum()\n",
    "    .loc[\"wkcomp\"][[\"CumPaidLoss\", \"EarnedPremNet\"]]\n",
    ")\n",
    "\n",
    "patterns = cl.Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"dev\",\n",
    "            cl.Development(\n",
    "                average=[\"simple\"] * 5 + [\"volume\"] * 4,\n",
    "                n_periods=7,\n",
    "                drop_valuation=\"1995\",\n",
    "            ),\n",
    "        ),\n",
    "        (\"tail\", cl.TailCurve(curve=\"inverse_power\", extrap_periods=80)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cc = cl.CapeCod(decay=0.8, trend=0.02).fit(\n",
    "    X=patterns.fit_transform(wkcomp[\"CumPaidLoss\"]),\n",
    "    sample_weight=wkcomp[\"EarnedPremNet\"].latest_diagonal,\n",
    ")\n",
    "\n",
    "cc.ultimate_.plot(\n",
    "    kind=\"bar\",\n",
    "    color=\"hotpink\",\n",
    "    alpha=0.7,\n",
    "    legend=False,\n",
    "    title=\"Workers Compensation Industry Model\\n\" + \"Cape Cod with InversePower Tail\",\n",
    ").set(xlabel=\"Accident Year\", ylabel=\"Ultimates\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
