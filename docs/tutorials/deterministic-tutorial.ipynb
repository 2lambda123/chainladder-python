{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Deterministic Methods\n",
    "### Getting Started\n",
    "This tutorial focuses on using deterministic methods to square a triangle. \n",
    "\n",
    "Note that a lot of the examples shown here might not be applicable in a real world scenario, and is only meant to demonstrate some of the functionalities included in the package. The user should always exercise their best actuarial judgement, and follow any applicable laws, the Code of Professional Conduct, and applicable Actuarial Standards of Practice.\n",
    "\n",
    "Be sure to make sure your packages are updated. For more info on how to update your pakages, visit [Keeping Packages Updated](https://chainladder-python.readthedocs.io/en/latest/install.html#keeping-packages-updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "pandas: 1.3.1\n",
      "numpy: 1.20.3\n",
      "chainladder: 0.8.6\n"
     ]
    }
   ],
   "source": [
    "# Black linter, optional\n",
    "%load_ext lab_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chainladder as cl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"pandas: \" + pd.__version__)\n",
    "print(\"numpy: \" + np.__version__)\n",
    "print(\"chainladder: \" + cl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Chainladder Method\n",
    "\n",
    "The basic chainladder method is entirely specified by its development pattern selections. For this reason, the `Chainladder` estimator takes no additional assumptions, i.e. no additional arguments. Let's start by loading an example dataset and creating an Triangle with `Development` patterns and a `TailCurve`.  Recall, we can bundle these two estimators into a single `Pipeline` if we wish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "genins = cl.load_sample(\"genins\")\n",
    "\n",
    "genins_dev = cl.Pipeline(\n",
    "    [(\"dev\", cl.Development()), (\"tail\", cl.TailCurve())]\n",
    ").fit_transform(genins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the basic `Chainladder` estimator to estimate `ultimate_` values of our `Triangle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>4,016,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>5,594,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>5,537,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>5,454,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>5,001,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>5,261,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>5,827,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>6,984,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>5,808,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>5,116,430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "              2261\n",
       "2001  4.016553e+06\n",
       "2002  5.594009e+06\n",
       "2003  5.537497e+06\n",
       "2004  5.454190e+06\n",
       "2005  5.001513e+06\n",
       "2006  5.261947e+06\n",
       "2007  5.827759e+06\n",
       "2008  6.984945e+06\n",
       "2009  5.808708e+06\n",
       "2010  5.116430e+06"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model = cl.Chainladder().fit(genins_dev)\n",
    "genins_model.ultimate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the `ibnr_`.  Techincally the term IBNR is reserved for Incurred but not Reported, but the `chainladder` models use it to describe the difference between the ultimate and the latest evaluation period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>115,090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>254,924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>628,182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>865,922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>1,128,202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>1,570,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>2,344,629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>4,120,447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>4,445,414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>4,772,416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "              2261\n",
       "2001  1.150899e+05\n",
       "2002  2.549240e+05\n",
       "2003  6.281822e+05\n",
       "2004  8.659217e+05\n",
       "2005  1.128202e+06\n",
       "2006  1.570235e+06\n",
       "2007  2.344629e+06\n",
       "2008  4.120447e+06\n",
       "2009  4.445414e+06\n",
       "2010  4.772416e+06"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.ibnr_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is often useful to see the completed `Triangle` and this can be accomplished by inspecting the `full_triangle_`.  As with most other estimator properties, the `full_triangle_` is itself a `Triangle` and can be manipulated as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>357,848</td>\n",
       "      <td>1,124,788</td>\n",
       "      <td>1,735,330</td>\n",
       "      <td>2,218,270</td>\n",
       "      <td>2,745,596</td>\n",
       "      <td>3,319,994</td>\n",
       "      <td>3,466,336</td>\n",
       "      <td>3,606,286</td>\n",
       "      <td>3,833,515</td>\n",
       "      <td>3,901,463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>352,118</td>\n",
       "      <td>1,236,139</td>\n",
       "      <td>2,170,033</td>\n",
       "      <td>3,353,322</td>\n",
       "      <td>3,799,067</td>\n",
       "      <td>4,120,063</td>\n",
       "      <td>4,647,867</td>\n",
       "      <td>4,914,039</td>\n",
       "      <td>5,339,085</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>290,507</td>\n",
       "      <td>1,292,306</td>\n",
       "      <td>2,218,525</td>\n",
       "      <td>3,235,179</td>\n",
       "      <td>3,985,995</td>\n",
       "      <td>4,132,918</td>\n",
       "      <td>4,628,910</td>\n",
       "      <td>4,909,315</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>310,608</td>\n",
       "      <td>1,418,858</td>\n",
       "      <td>2,195,047</td>\n",
       "      <td>3,757,447</td>\n",
       "      <td>4,029,929</td>\n",
       "      <td>4,381,982</td>\n",
       "      <td>4,588,268</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>443,160</td>\n",
       "      <td>1,136,350</td>\n",
       "      <td>2,128,333</td>\n",
       "      <td>2,897,821</td>\n",
       "      <td>3,402,672</td>\n",
       "      <td>3,873,311</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>396,132</td>\n",
       "      <td>1,333,217</td>\n",
       "      <td>2,180,715</td>\n",
       "      <td>2,985,752</td>\n",
       "      <td>3,691,712</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>440,832</td>\n",
       "      <td>1,288,463</td>\n",
       "      <td>2,419,861</td>\n",
       "      <td>3,483,130</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>359,480</td>\n",
       "      <td>1,421,128</td>\n",
       "      <td>2,864,498</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>376,686</td>\n",
       "      <td>1,363,294</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>344,014</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "           12         24         36         48         60         72         84         96         108        120\n",
       "2001  357848.0  1124788.0  1735330.0  2218270.0  2745596.0  3319994.0  3466336.0  3606286.0  3833515.0  3901463.0\n",
       "2002  352118.0  1236139.0  2170033.0  3353322.0  3799067.0  4120063.0  4647867.0  4914039.0  5339085.0        NaN\n",
       "2003  290507.0  1292306.0  2218525.0  3235179.0  3985995.0  4132918.0  4628910.0  4909315.0        NaN        NaN\n",
       "2004  310608.0  1418858.0  2195047.0  3757447.0  4029929.0  4381982.0  4588268.0        NaN        NaN        NaN\n",
       "2005  443160.0  1136350.0  2128333.0  2897821.0  3402672.0  3873311.0        NaN        NaN        NaN        NaN\n",
       "2006  396132.0  1333217.0  2180715.0  2985752.0  3691712.0        NaN        NaN        NaN        NaN        NaN\n",
       "2007  440832.0  1288463.0  2419861.0  3483130.0        NaN        NaN        NaN        NaN        NaN        NaN\n",
       "2008  359480.0  1421128.0  2864498.0        NaN        NaN        NaN        NaN        NaN        NaN        NaN\n",
       "2009  376686.0  1363294.0        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN\n",
       "2010  344014.0        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "      <th>120</th>\n",
       "      <th>132</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>357,848</td>\n",
       "      <td>1,124,788</td>\n",
       "      <td>1,735,330</td>\n",
       "      <td>2,218,270</td>\n",
       "      <td>2,745,596</td>\n",
       "      <td>3,319,994</td>\n",
       "      <td>3,466,336</td>\n",
       "      <td>3,606,286</td>\n",
       "      <td>3,833,515</td>\n",
       "      <td>3,901,463</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>4,016,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>352,118</td>\n",
       "      <td>1,236,139</td>\n",
       "      <td>2,170,033</td>\n",
       "      <td>3,353,322</td>\n",
       "      <td>3,799,067</td>\n",
       "      <td>4,120,063</td>\n",
       "      <td>4,647,867</td>\n",
       "      <td>4,914,039</td>\n",
       "      <td>5,339,085</td>\n",
       "      <td>5,433,719</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,594,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>290,507</td>\n",
       "      <td>1,292,306</td>\n",
       "      <td>2,218,525</td>\n",
       "      <td>3,235,179</td>\n",
       "      <td>3,985,995</td>\n",
       "      <td>4,132,918</td>\n",
       "      <td>4,628,910</td>\n",
       "      <td>4,909,315</td>\n",
       "      <td>5,285,148</td>\n",
       "      <td>5,378,826</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,537,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>310,608</td>\n",
       "      <td>1,418,858</td>\n",
       "      <td>2,195,047</td>\n",
       "      <td>3,757,447</td>\n",
       "      <td>4,029,929</td>\n",
       "      <td>4,381,982</td>\n",
       "      <td>4,588,268</td>\n",
       "      <td>4,835,458</td>\n",
       "      <td>5,205,637</td>\n",
       "      <td>5,297,906</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,454,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>443,160</td>\n",
       "      <td>1,136,350</td>\n",
       "      <td>2,128,333</td>\n",
       "      <td>2,897,821</td>\n",
       "      <td>3,402,672</td>\n",
       "      <td>3,873,311</td>\n",
       "      <td>4,207,459</td>\n",
       "      <td>4,434,133</td>\n",
       "      <td>4,773,589</td>\n",
       "      <td>4,858,200</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>5,001,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>396,132</td>\n",
       "      <td>1,333,217</td>\n",
       "      <td>2,180,715</td>\n",
       "      <td>2,985,752</td>\n",
       "      <td>3,691,712</td>\n",
       "      <td>4,074,999</td>\n",
       "      <td>4,426,546</td>\n",
       "      <td>4,665,023</td>\n",
       "      <td>5,022,155</td>\n",
       "      <td>5,111,171</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,261,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>440,832</td>\n",
       "      <td>1,288,463</td>\n",
       "      <td>2,419,861</td>\n",
       "      <td>3,483,130</td>\n",
       "      <td>4,088,678</td>\n",
       "      <td>4,513,179</td>\n",
       "      <td>4,902,528</td>\n",
       "      <td>5,166,649</td>\n",
       "      <td>5,562,182</td>\n",
       "      <td>5,660,771</td>\n",
       "      <td>5,728,396</td>\n",
       "      <td>5,827,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>359,480</td>\n",
       "      <td>1,421,128</td>\n",
       "      <td>2,864,498</td>\n",
       "      <td>4,174,756</td>\n",
       "      <td>4,900,545</td>\n",
       "      <td>5,409,337</td>\n",
       "      <td>5,875,997</td>\n",
       "      <td>6,192,562</td>\n",
       "      <td>6,666,635</td>\n",
       "      <td>6,784,799</td>\n",
       "      <td>6,865,853</td>\n",
       "      <td>6,984,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>376,686</td>\n",
       "      <td>1,363,294</td>\n",
       "      <td>2,382,128</td>\n",
       "      <td>3,471,744</td>\n",
       "      <td>4,075,313</td>\n",
       "      <td>4,498,426</td>\n",
       "      <td>4,886,502</td>\n",
       "      <td>5,149,760</td>\n",
       "      <td>5,544,000</td>\n",
       "      <td>5,642,266</td>\n",
       "      <td>5,709,671</td>\n",
       "      <td>5,808,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>344,014</td>\n",
       "      <td>1,200,818</td>\n",
       "      <td>2,098,228</td>\n",
       "      <td>3,057,984</td>\n",
       "      <td>3,589,620</td>\n",
       "      <td>3,962,307</td>\n",
       "      <td>4,304,132</td>\n",
       "      <td>4,536,015</td>\n",
       "      <td>4,883,270</td>\n",
       "      <td>4,969,825</td>\n",
       "      <td>5,029,196</td>\n",
       "      <td>5,116,430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          12            24            36            48            60            72            84            96            108           120           132           9999\n",
       "2001  357848.0  1.124788e+06  1.735330e+06  2.218270e+06  2.745596e+06  3.319994e+06  3.466336e+06  3.606286e+06  3.833515e+06  3.901463e+06  3.948071e+06  4.016553e+06\n",
       "2002  352118.0  1.236139e+06  2.170033e+06  3.353322e+06  3.799067e+06  4.120063e+06  4.647867e+06  4.914039e+06  5.339085e+06  5.433719e+06  5.498632e+06  5.594009e+06\n",
       "2003  290507.0  1.292306e+06  2.218525e+06  3.235179e+06  3.985995e+06  4.132918e+06  4.628910e+06  4.909315e+06  5.285148e+06  5.378826e+06  5.443084e+06  5.537497e+06\n",
       "2004  310608.0  1.418858e+06  2.195047e+06  3.757447e+06  4.029929e+06  4.381982e+06  4.588268e+06  4.835458e+06  5.205637e+06  5.297906e+06  5.361197e+06  5.454190e+06\n",
       "2005  443160.0  1.136350e+06  2.128333e+06  2.897821e+06  3.402672e+06  3.873311e+06  4.207459e+06  4.434133e+06  4.773589e+06  4.858200e+06  4.916237e+06  5.001513e+06\n",
       "2006  396132.0  1.333217e+06  2.180715e+06  2.985752e+06  3.691712e+06  4.074999e+06  4.426546e+06  4.665023e+06  5.022155e+06  5.111171e+06  5.172231e+06  5.261947e+06\n",
       "2007  440832.0  1.288463e+06  2.419861e+06  3.483130e+06  4.088678e+06  4.513179e+06  4.902528e+06  5.166649e+06  5.562182e+06  5.660771e+06  5.728396e+06  5.827759e+06\n",
       "2008  359480.0  1.421128e+06  2.864498e+06  4.174756e+06  4.900545e+06  5.409337e+06  5.875997e+06  6.192562e+06  6.666635e+06  6.784799e+06  6.865853e+06  6.984945e+06\n",
       "2009  376686.0  1.363294e+06  2.382128e+06  3.471744e+06  4.075313e+06  4.498426e+06  4.886502e+06  5.149760e+06  5.544000e+06  5.642266e+06  5.709671e+06  5.808708e+06\n",
       "2010  344014.0  1.200818e+06  2.098228e+06  3.057984e+06  3.589620e+06  3.962307e+06  4.304132e+06  4.536015e+06  4.883270e+06  4.969825e+06  5.029196e+06  5.116430e+06"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_triangle_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>357,848</td>\n",
       "      <td>1,124,788</td>\n",
       "      <td>1,735,330</td>\n",
       "      <td>2,218,270</td>\n",
       "      <td>2,745,596</td>\n",
       "      <td>3,319,994</td>\n",
       "      <td>3,466,336</td>\n",
       "      <td>3,606,286</td>\n",
       "      <td>3,833,515</td>\n",
       "      <td>3,901,463</td>\n",
       "      <td>...</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>4,016,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td></td>\n",
       "      <td>352,118</td>\n",
       "      <td>1,236,139</td>\n",
       "      <td>2,170,033</td>\n",
       "      <td>3,353,322</td>\n",
       "      <td>3,799,067</td>\n",
       "      <td>4,120,063</td>\n",
       "      <td>4,647,867</td>\n",
       "      <td>4,914,039</td>\n",
       "      <td>5,339,085</td>\n",
       "      <td>...</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,594,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>290,507</td>\n",
       "      <td>1,292,306</td>\n",
       "      <td>2,218,525</td>\n",
       "      <td>3,235,179</td>\n",
       "      <td>3,985,995</td>\n",
       "      <td>4,132,918</td>\n",
       "      <td>4,628,910</td>\n",
       "      <td>4,909,315</td>\n",
       "      <td>...</td>\n",
       "      <td>5,378,826</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,537,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>310,608</td>\n",
       "      <td>1,418,858</td>\n",
       "      <td>2,195,047</td>\n",
       "      <td>3,757,447</td>\n",
       "      <td>4,029,929</td>\n",
       "      <td>4,381,982</td>\n",
       "      <td>4,588,268</td>\n",
       "      <td>...</td>\n",
       "      <td>5,205,637</td>\n",
       "      <td>5,297,906</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,454,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>443,160</td>\n",
       "      <td>1,136,350</td>\n",
       "      <td>2,128,333</td>\n",
       "      <td>2,897,821</td>\n",
       "      <td>3,402,672</td>\n",
       "      <td>3,873,311</td>\n",
       "      <td>...</td>\n",
       "      <td>4,434,133</td>\n",
       "      <td>4,773,589</td>\n",
       "      <td>4,858,200</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>5,001,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>396,132</td>\n",
       "      <td>1,333,217</td>\n",
       "      <td>2,180,715</td>\n",
       "      <td>2,985,752</td>\n",
       "      <td>3,691,712</td>\n",
       "      <td>...</td>\n",
       "      <td>4,426,546</td>\n",
       "      <td>4,665,023</td>\n",
       "      <td>5,022,155</td>\n",
       "      <td>5,111,171</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,261,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>440,832</td>\n",
       "      <td>1,288,463</td>\n",
       "      <td>2,419,861</td>\n",
       "      <td>3,483,130</td>\n",
       "      <td>...</td>\n",
       "      <td>4,513,179</td>\n",
       "      <td>4,902,528</td>\n",
       "      <td>5,166,649</td>\n",
       "      <td>5,562,182</td>\n",
       "      <td>5,660,771</td>\n",
       "      <td>5,728,396</td>\n",
       "      <td>5,728,396</td>\n",
       "      <td>5,728,396</td>\n",
       "      <td>5,728,396</td>\n",
       "      <td>5,827,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>359,480</td>\n",
       "      <td>1,421,128</td>\n",
       "      <td>2,864,498</td>\n",
       "      <td>...</td>\n",
       "      <td>4,900,545</td>\n",
       "      <td>5,409,337</td>\n",
       "      <td>5,875,997</td>\n",
       "      <td>6,192,562</td>\n",
       "      <td>6,666,635</td>\n",
       "      <td>6,784,799</td>\n",
       "      <td>6,865,853</td>\n",
       "      <td>6,865,853</td>\n",
       "      <td>6,865,853</td>\n",
       "      <td>6,984,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>376,686</td>\n",
       "      <td>1,363,294</td>\n",
       "      <td>...</td>\n",
       "      <td>3,471,744</td>\n",
       "      <td>4,075,313</td>\n",
       "      <td>4,498,426</td>\n",
       "      <td>4,886,502</td>\n",
       "      <td>5,149,760</td>\n",
       "      <td>5,544,000</td>\n",
       "      <td>5,642,266</td>\n",
       "      <td>5,709,671</td>\n",
       "      <td>5,709,671</td>\n",
       "      <td>5,808,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>344,014</td>\n",
       "      <td>...</td>\n",
       "      <td>2,098,228</td>\n",
       "      <td>3,057,984</td>\n",
       "      <td>3,589,620</td>\n",
       "      <td>3,962,307</td>\n",
       "      <td>4,304,132</td>\n",
       "      <td>4,536,015</td>\n",
       "      <td>4,883,270</td>\n",
       "      <td>4,969,825</td>\n",
       "      <td>5,029,196</td>\n",
       "      <td>5,116,430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          2001       2002       2003       2004       2005       2006       2007       2008       2009       2010          2011          2012          2013          2014          2015          2016          2017          2018          2019          2020          2261\n",
       "2001  357848.0  1124788.0  1735330.0  2218270.0  2745596.0  3319994.0  3466336.0  3606286.0  3833515.0  3901463.0  3.948071e+06  3.948071e+06  3.948071e+06  3.948071e+06  3.948071e+06  3.948071e+06  3.948071e+06  3.948071e+06  3.948071e+06  3.948071e+06  4.016553e+06\n",
       "2002       NaN   352118.0  1236139.0  2170033.0  3353322.0  3799067.0  4120063.0  4647867.0  4914039.0  5339085.0  5.433719e+06  5.498632e+06  5.498632e+06  5.498632e+06  5.498632e+06  5.498632e+06  5.498632e+06  5.498632e+06  5.498632e+06  5.498632e+06  5.594009e+06\n",
       "2003       NaN        NaN   290507.0  1292306.0  2218525.0  3235179.0  3985995.0  4132918.0  4628910.0  4909315.0  5.285148e+06  5.378826e+06  5.443084e+06  5.443084e+06  5.443084e+06  5.443084e+06  5.443084e+06  5.443084e+06  5.443084e+06  5.443084e+06  5.537497e+06\n",
       "2004       NaN        NaN        NaN   310608.0  1418858.0  2195047.0  3757447.0  4029929.0  4381982.0  4588268.0  4.835458e+06  5.205637e+06  5.297906e+06  5.361197e+06  5.361197e+06  5.361197e+06  5.361197e+06  5.361197e+06  5.361197e+06  5.361197e+06  5.454190e+06\n",
       "2005       NaN        NaN        NaN        NaN   443160.0  1136350.0  2128333.0  2897821.0  3402672.0  3873311.0  4.207459e+06  4.434133e+06  4.773589e+06  4.858200e+06  4.916237e+06  4.916237e+06  4.916237e+06  4.916237e+06  4.916237e+06  4.916237e+06  5.001513e+06\n",
       "2006       NaN        NaN        NaN        NaN        NaN   396132.0  1333217.0  2180715.0  2985752.0  3691712.0  4.074999e+06  4.426546e+06  4.665023e+06  5.022155e+06  5.111171e+06  5.172231e+06  5.172231e+06  5.172231e+06  5.172231e+06  5.172231e+06  5.261947e+06\n",
       "2007       NaN        NaN        NaN        NaN        NaN        NaN   440832.0  1288463.0  2419861.0  3483130.0  4.088678e+06  4.513179e+06  4.902528e+06  5.166649e+06  5.562182e+06  5.660771e+06  5.728396e+06  5.728396e+06  5.728396e+06  5.728396e+06  5.827759e+06\n",
       "2008       NaN        NaN        NaN        NaN        NaN        NaN        NaN   359480.0  1421128.0  2864498.0  4.174756e+06  4.900545e+06  5.409337e+06  5.875997e+06  6.192562e+06  6.666635e+06  6.784799e+06  6.865853e+06  6.865853e+06  6.865853e+06  6.984945e+06\n",
       "2009       NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN   376686.0  1363294.0  2.382128e+06  3.471744e+06  4.075313e+06  4.498426e+06  4.886502e+06  5.149760e+06  5.544000e+06  5.642266e+06  5.709671e+06  5.709671e+06  5.808708e+06\n",
       "2010       NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN        NaN   344014.0  1.200818e+06  2.098228e+06  3.057984e+06  3.589620e+06  3.962307e+06  4.304132e+06  4.536015e+06  4.883270e+06  4.969825e+06  5.029196e+06  5.116430e+06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_triangle_.dev_to_val()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the calendar year of our ultimates.  While ultimates will generally be realized before this date, the `chainladder` package picks the highest allowable date available for its `ultimate_` valuation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2261-12-31 23:59:59.999999999')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_triangle_.valuation_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further manipulate the \"triangle\", such as applying `cum_to_incr()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2001</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>...</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>357,848</td>\n",
       "      <td>766,940</td>\n",
       "      <td>610,542</td>\n",
       "      <td>482,940</td>\n",
       "      <td>527,326</td>\n",
       "      <td>574,398</td>\n",
       "      <td>146,342</td>\n",
       "      <td>139,950</td>\n",
       "      <td>227,229</td>\n",
       "      <td>67,948</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>68,482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td></td>\n",
       "      <td>352,118</td>\n",
       "      <td>884,021</td>\n",
       "      <td>933,894</td>\n",
       "      <td>1,183,289</td>\n",
       "      <td>445,745</td>\n",
       "      <td>320,996</td>\n",
       "      <td>527,804</td>\n",
       "      <td>266,172</td>\n",
       "      <td>425,046</td>\n",
       "      <td>...</td>\n",
       "      <td>64,913</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>95,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>290,507</td>\n",
       "      <td>1,001,799</td>\n",
       "      <td>926,219</td>\n",
       "      <td>1,016,654</td>\n",
       "      <td>750,816</td>\n",
       "      <td>146,923</td>\n",
       "      <td>495,992</td>\n",
       "      <td>280,405</td>\n",
       "      <td>...</td>\n",
       "      <td>93,678</td>\n",
       "      <td>64,257</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>94,413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>310,608</td>\n",
       "      <td>1,108,250</td>\n",
       "      <td>776,189</td>\n",
       "      <td>1,562,400</td>\n",
       "      <td>272,482</td>\n",
       "      <td>352,053</td>\n",
       "      <td>206,286</td>\n",
       "      <td>...</td>\n",
       "      <td>370,179</td>\n",
       "      <td>92,268</td>\n",
       "      <td>63,291</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>92,993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>443,160</td>\n",
       "      <td>693,190</td>\n",
       "      <td>991,983</td>\n",
       "      <td>769,488</td>\n",
       "      <td>504,851</td>\n",
       "      <td>470,639</td>\n",
       "      <td>...</td>\n",
       "      <td>226,674</td>\n",
       "      <td>339,456</td>\n",
       "      <td>84,611</td>\n",
       "      <td>58,038</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>85,275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>396,132</td>\n",
       "      <td>937,085</td>\n",
       "      <td>847,498</td>\n",
       "      <td>805,037</td>\n",
       "      <td>705,960</td>\n",
       "      <td>...</td>\n",
       "      <td>351,548</td>\n",
       "      <td>238,477</td>\n",
       "      <td>357,132</td>\n",
       "      <td>89,016</td>\n",
       "      <td>61,060</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>89,715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>440,832</td>\n",
       "      <td>847,631</td>\n",
       "      <td>1,131,398</td>\n",
       "      <td>1,063,269</td>\n",
       "      <td>...</td>\n",
       "      <td>424,501</td>\n",
       "      <td>389,349</td>\n",
       "      <td>264,121</td>\n",
       "      <td>395,534</td>\n",
       "      <td>98,588</td>\n",
       "      <td>67,626</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>99,362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>359,480</td>\n",
       "      <td>1,061,648</td>\n",
       "      <td>1,443,370</td>\n",
       "      <td>...</td>\n",
       "      <td>725,788</td>\n",
       "      <td>508,792</td>\n",
       "      <td>466,660</td>\n",
       "      <td>316,566</td>\n",
       "      <td>474,073</td>\n",
       "      <td>118,164</td>\n",
       "      <td>81,054</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>119,092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>376,686</td>\n",
       "      <td>986,608</td>\n",
       "      <td>...</td>\n",
       "      <td>1,089,616</td>\n",
       "      <td>603,569</td>\n",
       "      <td>423,113</td>\n",
       "      <td>388,076</td>\n",
       "      <td>263,257</td>\n",
       "      <td>394,241</td>\n",
       "      <td>98,266</td>\n",
       "      <td>67,405</td>\n",
       "      <td></td>\n",
       "      <td>99,038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>344,014</td>\n",
       "      <td>...</td>\n",
       "      <td>897,410</td>\n",
       "      <td>959,756</td>\n",
       "      <td>531,636</td>\n",
       "      <td>372,687</td>\n",
       "      <td>341,826</td>\n",
       "      <td>231,882</td>\n",
       "      <td>347,255</td>\n",
       "      <td>86,555</td>\n",
       "      <td>59,371</td>\n",
       "      <td>87,234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          2001      2002      2003       2004       2005       2006       2007      2008       2009       2010          2011          2012           2013           2014           2015           2016           2017           2018          2019          2020           2261\n",
       "2001  357848.0  766940.0  610542.0   482940.0   527326.0   574398.0   146342.0  139950.0   227229.0    67948.0  4.660832e+04           NaN            NaN            NaN            NaN            NaN            NaN            NaN           NaN           NaN   68481.607479\n",
       "2002       NaN  352118.0  884021.0   933894.0  1183289.0   445745.0   320996.0  527804.0   266172.0   425046.0  9.463381e+04  6.491321e+04            NaN            NaN            NaN            NaN            NaN            NaN           NaN           NaN   95376.990378\n",
       "2003       NaN       NaN  290507.0  1001799.0   926219.0  1016654.0   750816.0  146923.0   495992.0   280405.0  3.758335e+05  9.367780e+04   64257.444029            NaN            NaN            NaN            NaN            NaN           NaN           NaN   94413.472765\n",
       "2004       NaN       NaN       NaN   310608.0  1108250.0   776189.0  1562400.0  272482.0   352053.0   206286.0  2.471900e+05  3.701793e+05   92268.491259   63290.738238            NaN            NaN            NaN            NaN           NaN           NaN   92993.091793\n",
       "2005       NaN       NaN       NaN        NaN   443160.0   693190.0   991983.0  769488.0   504851.0   470639.0  3.341481e+05  2.266741e+05  339455.859834   84610.554829   58037.845908            NaN            NaN            NaN           NaN           NaN   85275.016254\n",
       "2006       NaN       NaN       NaN        NaN        NaN   396132.0   937085.0  847498.0   805037.0   705960.0  3.832866e+05  3.515475e+05  238477.319189  357131.701211   89016.319828   61059.940618            NaN            NaN           NaN           NaN   89715.380493\n",
       "2007       NaN       NaN       NaN        NaN        NaN        NaN   440832.0  847631.0  1131398.0  1063269.0  6.055481e+05  4.245010e+05  389349.093199  264120.547162  395533.716386   98588.155801   67625.655054            NaN           NaN           NaN   99362.385761\n",
       "2008       NaN       NaN       NaN        NaN        NaN        NaN        NaN  359480.0  1061648.0  1443370.0  1.310258e+06  7.257885e+05  508791.855239  466660.022126  316565.525733  474072.692256  118164.268959   81053.713068           NaN           NaN  119092.233545\n",
       "2009       NaN       NaN       NaN        NaN        NaN        NaN        NaN       NaN   376686.0   986608.0  1.018834e+06  1.089616e+06  603568.642933  423113.361911  388076.359317  263257.169860  394240.765738   98265.883351  67404.595177           NaN   99037.582449\n",
       "2010       NaN       NaN       NaN        NaN        NaN        NaN        NaN       NaN        NaN   344014.0  8.568035e+05  8.974101e+05  959756.260737  531635.730480  372686.990732  341825.674980  231882.354130  347255.411513  86554.620238  59371.360017   87234.348747"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_triangle_.dev_to_val().cum_to_incr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful property is `full_expectation_`. Similar to the `full_triangle`, it \"squares\" the `Triangle`, but replaces the known data with expected values implied by the model and development pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "      <th>120</th>\n",
       "      <th>132</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>270,061</td>\n",
       "      <td>942,678</td>\n",
       "      <td>1,647,172</td>\n",
       "      <td>2,400,610</td>\n",
       "      <td>2,817,960</td>\n",
       "      <td>3,110,531</td>\n",
       "      <td>3,378,874</td>\n",
       "      <td>3,560,909</td>\n",
       "      <td>3,833,515</td>\n",
       "      <td>3,901,463</td>\n",
       "      <td>3,948,071</td>\n",
       "      <td>4,016,553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>376,125</td>\n",
       "      <td>1,312,904</td>\n",
       "      <td>2,294,081</td>\n",
       "      <td>3,343,423</td>\n",
       "      <td>3,924,682</td>\n",
       "      <td>4,332,157</td>\n",
       "      <td>4,705,889</td>\n",
       "      <td>4,959,416</td>\n",
       "      <td>5,339,085</td>\n",
       "      <td>5,433,719</td>\n",
       "      <td>5,498,632</td>\n",
       "      <td>5,594,009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>372,325</td>\n",
       "      <td>1,299,641</td>\n",
       "      <td>2,270,905</td>\n",
       "      <td>3,309,647</td>\n",
       "      <td>3,885,035</td>\n",
       "      <td>4,288,393</td>\n",
       "      <td>4,658,349</td>\n",
       "      <td>4,909,315</td>\n",
       "      <td>5,285,148</td>\n",
       "      <td>5,378,826</td>\n",
       "      <td>5,443,084</td>\n",
       "      <td>5,537,497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>366,724</td>\n",
       "      <td>1,280,089</td>\n",
       "      <td>2,236,741</td>\n",
       "      <td>3,259,856</td>\n",
       "      <td>3,826,587</td>\n",
       "      <td>4,223,877</td>\n",
       "      <td>4,588,268</td>\n",
       "      <td>4,835,458</td>\n",
       "      <td>5,205,637</td>\n",
       "      <td>5,297,906</td>\n",
       "      <td>5,361,197</td>\n",
       "      <td>5,454,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>336,287</td>\n",
       "      <td>1,173,846</td>\n",
       "      <td>2,051,100</td>\n",
       "      <td>2,989,300</td>\n",
       "      <td>3,508,995</td>\n",
       "      <td>3,873,311</td>\n",
       "      <td>4,207,459</td>\n",
       "      <td>4,434,133</td>\n",
       "      <td>4,773,589</td>\n",
       "      <td>4,858,200</td>\n",
       "      <td>4,916,237</td>\n",
       "      <td>5,001,513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>353,798</td>\n",
       "      <td>1,234,970</td>\n",
       "      <td>2,157,903</td>\n",
       "      <td>3,144,956</td>\n",
       "      <td>3,691,712</td>\n",
       "      <td>4,074,999</td>\n",
       "      <td>4,426,546</td>\n",
       "      <td>4,665,023</td>\n",
       "      <td>5,022,155</td>\n",
       "      <td>5,111,171</td>\n",
       "      <td>5,172,231</td>\n",
       "      <td>5,261,947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>391,842</td>\n",
       "      <td>1,367,765</td>\n",
       "      <td>2,389,941</td>\n",
       "      <td>3,483,130</td>\n",
       "      <td>4,088,678</td>\n",
       "      <td>4,513,179</td>\n",
       "      <td>4,902,528</td>\n",
       "      <td>5,166,649</td>\n",
       "      <td>5,562,182</td>\n",
       "      <td>5,660,771</td>\n",
       "      <td>5,728,396</td>\n",
       "      <td>5,827,759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>469,648</td>\n",
       "      <td>1,639,355</td>\n",
       "      <td>2,864,498</td>\n",
       "      <td>4,174,756</td>\n",
       "      <td>4,900,545</td>\n",
       "      <td>5,409,337</td>\n",
       "      <td>5,875,997</td>\n",
       "      <td>6,192,562</td>\n",
       "      <td>6,666,635</td>\n",
       "      <td>6,784,799</td>\n",
       "      <td>6,865,853</td>\n",
       "      <td>6,984,945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>390,561</td>\n",
       "      <td>1,363,294</td>\n",
       "      <td>2,382,128</td>\n",
       "      <td>3,471,744</td>\n",
       "      <td>4,075,313</td>\n",
       "      <td>4,498,426</td>\n",
       "      <td>4,886,502</td>\n",
       "      <td>5,149,760</td>\n",
       "      <td>5,544,000</td>\n",
       "      <td>5,642,266</td>\n",
       "      <td>5,709,671</td>\n",
       "      <td>5,808,708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>344,014</td>\n",
       "      <td>1,200,818</td>\n",
       "      <td>2,098,228</td>\n",
       "      <td>3,057,984</td>\n",
       "      <td>3,589,620</td>\n",
       "      <td>3,962,307</td>\n",
       "      <td>4,304,132</td>\n",
       "      <td>4,536,015</td>\n",
       "      <td>4,883,270</td>\n",
       "      <td>4,969,825</td>\n",
       "      <td>5,029,196</td>\n",
       "      <td>5,116,430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "               12            24            36            48            60            72            84            96            108           120           132           9999\n",
       "2001  270061.415645  9.426781e+05  1.647172e+06  2.400610e+06  2.817960e+06  3.110531e+06  3.378874e+06  3.560909e+06  3.833515e+06  3.901463e+06  3.948071e+06  4.016553e+06\n",
       "2002  376125.006253  1.312904e+06  2.294081e+06  3.343423e+06  3.924682e+06  4.332157e+06  4.705889e+06  4.959416e+06  5.339085e+06  5.433719e+06  5.498632e+06  5.594009e+06\n",
       "2003  372325.315504  1.299641e+06  2.270905e+06  3.309647e+06  3.885035e+06  4.288393e+06  4.658349e+06  4.909315e+06  5.285148e+06  5.378826e+06  5.443084e+06  5.537497e+06\n",
       "2004  366723.956096  1.280089e+06  2.236741e+06  3.259856e+06  3.826587e+06  4.223877e+06  4.588268e+06  4.835458e+06  5.205637e+06  5.297906e+06  5.361197e+06  5.454190e+06\n",
       "2005  336287.252245  1.173846e+06  2.051100e+06  2.989300e+06  3.508995e+06  3.873311e+06  4.207459e+06  4.434133e+06  4.773589e+06  4.858200e+06  4.916237e+06  5.001513e+06\n",
       "2006  353798.100727  1.234970e+06  2.157903e+06  3.144956e+06  3.691712e+06  4.074999e+06  4.426546e+06  4.665023e+06  5.022155e+06  5.111171e+06  5.172231e+06  5.261947e+06\n",
       "2007  391841.657172  1.367765e+06  2.389941e+06  3.483130e+06  4.088678e+06  4.513179e+06  4.902528e+06  5.166649e+06  5.562182e+06  5.660771e+06  5.728396e+06  5.827759e+06\n",
       "2008  469647.520951  1.639355e+06  2.864498e+06  4.174756e+06  4.900545e+06  5.409337e+06  5.875997e+06  6.192562e+06  6.666635e+06  6.784799e+06  6.865853e+06  6.984945e+06\n",
       "2009  390560.775407  1.363294e+06  2.382128e+06  3.471744e+06  4.075313e+06  4.498426e+06  4.886502e+06  5.149760e+06  5.544000e+06  5.642266e+06  5.709671e+06  5.808708e+06\n",
       "2010  344014.000000  1.200818e+06  2.098228e+06  3.057984e+06  3.589620e+06  3.962307e+06  4.304132e+06  4.536015e+06  4.883270e+06  4.969825e+06  5.029196e+06  5.116430e+06"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_expectation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some clever arithmetic, we can use these objects to give us other useful information.  For example, we can retrospectively review the actual `Triangle` against its modeled expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "      <th>120</th>\n",
       "      <th>132</th>\n",
       "      <th>9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>87,787</td>\n",
       "      <td>182,110</td>\n",
       "      <td>88,158</td>\n",
       "      <td>-182,340</td>\n",
       "      <td>-72,364</td>\n",
       "      <td>209,463</td>\n",
       "      <td>87,462</td>\n",
       "      <td>45,377</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>-24,007</td>\n",
       "      <td>-76,765</td>\n",
       "      <td>-124,048</td>\n",
       "      <td>9,899</td>\n",
       "      <td>-125,615</td>\n",
       "      <td>-212,094</td>\n",
       "      <td>-58,022</td>\n",
       "      <td>-45,377</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-81,818</td>\n",
       "      <td>-7,335</td>\n",
       "      <td>-52,380</td>\n",
       "      <td>-74,468</td>\n",
       "      <td>100,960</td>\n",
       "      <td>-155,475</td>\n",
       "      <td>-29,439</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-56,116</td>\n",
       "      <td>138,769</td>\n",
       "      <td>-41,694</td>\n",
       "      <td>497,591</td>\n",
       "      <td>203,342</td>\n",
       "      <td>158,105</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>106,873</td>\n",
       "      <td>-37,496</td>\n",
       "      <td>77,233</td>\n",
       "      <td>-91,479</td>\n",
       "      <td>-106,323</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>42,334</td>\n",
       "      <td>98,247</td>\n",
       "      <td>22,812</td>\n",
       "      <td>-159,204</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>48,990</td>\n",
       "      <td>-79,302</td>\n",
       "      <td>29,920</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-110,168</td>\n",
       "      <td>-218,227</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-13,875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td></td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "               12            24            36            48            60            72            84            96            108           120           132           9999\n",
       "2001   87786.584355  1.821099e+05  8.815770e+04 -1.823400e+05 -7.236421e+04  2.094632e+05  8.746170e+04  4.537702e+04  4.656613e-10           NaN           NaN           NaN\n",
       "2002  -24007.006253 -7.676541e+04 -1.240477e+05  9.899296e+03 -1.256155e+05 -2.120939e+05 -5.802227e+04 -4.537702e+04           NaN           NaN           NaN           NaN\n",
       "2003  -81818.315504 -7.335184e+03 -5.238046e+04 -7.446777e+04  1.009605e+05 -1.554745e+05 -2.943943e+04           NaN -9.313226e-10 -9.313226e-10           NaN           NaN\n",
       "2004  -56115.956096  1.387690e+05 -4.169437e+04  4.975914e+05  2.033420e+05  1.581052e+05           NaN           NaN -9.313226e-10 -9.313226e-10 -9.313226e-10 -9.313226e-10\n",
       "2005  106872.747755 -3.749648e+04  7.723272e+04 -9.147888e+04 -1.063228e+05           NaN           NaN           NaN -9.313226e-10           NaN -9.313226e-10 -9.313226e-10\n",
       "2006   42333.899273  9.824703e+04  2.281166e+04 -1.592040e+05           NaN -4.656613e-10 -9.313226e-10 -9.313226e-10 -9.313226e-10 -1.862645e-09 -1.862645e-09 -1.862645e-09\n",
       "2007   48990.342828 -7.930205e+04  2.992047e+04           NaN           NaN           NaN -9.313226e-10 -9.313226e-10           NaN -2.793968e-09 -1.862645e-09 -1.862645e-09\n",
       "2008 -110167.520951 -2.182267e+05           NaN           NaN           NaN           NaN -9.313226e-10 -1.862645e-09 -1.862645e-09 -1.862645e-09 -2.793968e-09 -1.862645e-09\n",
       "2009  -13874.775407           NaN           NaN  4.656613e-10           NaN -9.313226e-10           NaN -9.313226e-10 -1.862645e-09           NaN -9.313226e-10           NaN\n",
       "2010            NaN -2.328306e-10 -4.656613e-10 -9.313226e-10 -2.328306e-09  4.656613e-10 -2.793968e-09  1.862645e-09  1.862645e-09  2.793968e-09 -1.862645e-09  3.725290e-09"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genins_model.full_triangle_ - genins_model.full_expectation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also apply a heatmap over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f2d76_row0_col0, #T_f2d76_row3_col1 {\n",
       "  background-color: #dd5f4b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row0_col1, #T_f2d76_row0_col2, #T_f2d76_row0_col5, #T_f2d76_row0_col6, #T_f2d76_row0_col7, #T_f2d76_row3_col3, #T_f2d76_row3_col4, #T_f2d76_row3_col10, #T_f2d76_row4_col0, #T_f2d76_row4_col10, #T_f2d76_row8_col10, #T_f2d76_row9_col8, #T_f2d76_row9_col9, #T_f2d76_row9_col11 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row0_col3, #T_f2d76_row1_col2, #T_f2d76_row1_col4, #T_f2d76_row1_col5, #T_f2d76_row1_col6, #T_f2d76_row1_col7, #T_f2d76_row6_col9, #T_f2d76_row7_col0, #T_f2d76_row7_col1, #T_f2d76_row7_col10 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row0_col4, #T_f2d76_row5_col10, #T_f2d76_row6_col10, #T_f2d76_row9_col10 {\n",
       "  background-color: #c0d4f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row0_col8, #T_f2d76_row1_col3, #T_f2d76_row4_col2 {\n",
       "  background-color: #e26952;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row0_col9, #T_f2d76_row0_col10, #T_f2d76_row0_col11, #T_f2d76_row1_col8, #T_f2d76_row1_col9, #T_f2d76_row1_col10, #T_f2d76_row1_col11, #T_f2d76_row2_col1, #T_f2d76_row2_col7, #T_f2d76_row2_col8, #T_f2d76_row2_col10, #T_f2d76_row2_col11, #T_f2d76_row3_col6, #T_f2d76_row3_col7, #T_f2d76_row3_col8, #T_f2d76_row4_col5, #T_f2d76_row4_col6, #T_f2d76_row4_col7, #T_f2d76_row4_col8, #T_f2d76_row4_col9, #T_f2d76_row5_col4, #T_f2d76_row5_col5, #T_f2d76_row5_col7, #T_f2d76_row5_col8, #T_f2d76_row6_col3, #T_f2d76_row6_col4, #T_f2d76_row6_col5, #T_f2d76_row6_col7, #T_f2d76_row6_col8, #T_f2d76_row7_col2, #T_f2d76_row7_col3, #T_f2d76_row7_col4, #T_f2d76_row7_col5, #T_f2d76_row8_col0, #T_f2d76_row8_col1, #T_f2d76_row8_col2, #T_f2d76_row8_col4, #T_f2d76_row8_col6, #T_f2d76_row8_col7, #T_f2d76_row8_col9, #T_f2d76_row8_col11, #T_f2d76_row9_col0 {\n",
       "  background-color: #dddcdc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row1_col0, #T_f2d76_row4_col1 {\n",
       "  background-color: #b9d0f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row1_col1, #T_f2d76_row3_col0 {\n",
       "  background-color: #8db0fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row2_col0, #T_f2d76_row6_col1 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row2_col2, #T_f2d76_row5_col3 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row2_col3, #T_f2d76_row9_col2 {\n",
       "  background-color: #c9d7f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row2_col4 {\n",
       "  background-color: #ee8468;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row2_col5, #T_f2d76_row2_col6, #T_f2d76_row7_col7 {\n",
       "  background-color: #6f92f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row2_col9, #T_f2d76_row3_col9, #T_f2d76_row3_col11, #T_f2d76_row4_col11 {\n",
       "  background-color: #f7ac8e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row3_col2, #T_f2d76_row4_col3 {\n",
       "  background-color: #9abbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row3_col5, #T_f2d76_row9_col7 {\n",
       "  background-color: #e7745b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row4_col4, #T_f2d76_row5_col11, #T_f2d76_row6_col11, #T_f2d76_row7_col11 {\n",
       "  background-color: #7b9ff9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row5_col0, #T_f2d76_row9_col1 {\n",
       "  background-color: #f5c4ac;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row5_col1, #T_f2d76_row6_col0 {\n",
       "  background-color: #f4987a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row5_col2, #T_f2d76_row9_col3 {\n",
       "  background-color: #edd1c2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row5_col6, #T_f2d76_row6_col6, #T_f2d76_row7_col6, #T_f2d76_row9_col5 {\n",
       "  background-color: #f7b89c;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row5_col9, #T_f2d76_row7_col9 {\n",
       "  background-color: #9ebeff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row6_col2, #T_f2d76_row8_col3 {\n",
       "  background-color: #f7a889;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row7_col8, #T_f2d76_row8_col8 {\n",
       "  background-color: #506bda;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f2d76_row8_col5, #T_f2d76_row9_col6 {\n",
       "  background-color: #aac7fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f2d76_row9_col4 {\n",
       "  background-color: #f2cbb7;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f2d76_\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >12</th>\n",
       "      <th class=\"col_heading level0 col1\" >24</th>\n",
       "      <th class=\"col_heading level0 col2\" >36</th>\n",
       "      <th class=\"col_heading level0 col3\" >48</th>\n",
       "      <th class=\"col_heading level0 col4\" >60</th>\n",
       "      <th class=\"col_heading level0 col5\" >72</th>\n",
       "      <th class=\"col_heading level0 col6\" >84</th>\n",
       "      <th class=\"col_heading level0 col7\" >96</th>\n",
       "      <th class=\"col_heading level0 col8\" >108</th>\n",
       "      <th class=\"col_heading level0 col9\" >120</th>\n",
       "      <th class=\"col_heading level0 col10\" >132</th>\n",
       "      <th class=\"col_heading level0 col11\" >9999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row0\" class=\"row_heading level0 row0\" >2001</th>\n",
       "      <td id=\"T_f2d76_row0_col0\" class=\"data row0 col0\" >87,787</td>\n",
       "      <td id=\"T_f2d76_row0_col1\" class=\"data row0 col1\" >182,110</td>\n",
       "      <td id=\"T_f2d76_row0_col2\" class=\"data row0 col2\" >88,158</td>\n",
       "      <td id=\"T_f2d76_row0_col3\" class=\"data row0 col3\" >-182,340</td>\n",
       "      <td id=\"T_f2d76_row0_col4\" class=\"data row0 col4\" >-72,364</td>\n",
       "      <td id=\"T_f2d76_row0_col5\" class=\"data row0 col5\" >209,463</td>\n",
       "      <td id=\"T_f2d76_row0_col6\" class=\"data row0 col6\" >87,462</td>\n",
       "      <td id=\"T_f2d76_row0_col7\" class=\"data row0 col7\" >45,377</td>\n",
       "      <td id=\"T_f2d76_row0_col8\" class=\"data row0 col8\" >0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row1\" class=\"row_heading level0 row1\" >2002</th>\n",
       "      <td id=\"T_f2d76_row1_col0\" class=\"data row1 col0\" >-24,007</td>\n",
       "      <td id=\"T_f2d76_row1_col1\" class=\"data row1 col1\" >-76,765</td>\n",
       "      <td id=\"T_f2d76_row1_col2\" class=\"data row1 col2\" >-124,048</td>\n",
       "      <td id=\"T_f2d76_row1_col3\" class=\"data row1 col3\" >9,899</td>\n",
       "      <td id=\"T_f2d76_row1_col4\" class=\"data row1 col4\" >-125,615</td>\n",
       "      <td id=\"T_f2d76_row1_col5\" class=\"data row1 col5\" >-212,094</td>\n",
       "      <td id=\"T_f2d76_row1_col6\" class=\"data row1 col6\" >-58,022</td>\n",
       "      <td id=\"T_f2d76_row1_col7\" class=\"data row1 col7\" >-45,377</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row2\" class=\"row_heading level0 row2\" >2003</th>\n",
       "      <td id=\"T_f2d76_row2_col0\" class=\"data row2 col0\" >-81,818</td>\n",
       "      <td id=\"T_f2d76_row2_col1\" class=\"data row2 col1\" >-7,335</td>\n",
       "      <td id=\"T_f2d76_row2_col2\" class=\"data row2 col2\" >-52,380</td>\n",
       "      <td id=\"T_f2d76_row2_col3\" class=\"data row2 col3\" >-74,468</td>\n",
       "      <td id=\"T_f2d76_row2_col4\" class=\"data row2 col4\" >100,960</td>\n",
       "      <td id=\"T_f2d76_row2_col5\" class=\"data row2 col5\" >-155,475</td>\n",
       "      <td id=\"T_f2d76_row2_col6\" class=\"data row2 col6\" >-29,439</td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row2_col8\" class=\"data row2 col8\" >-0</td>\n",
       "      <td id=\"T_f2d76_row2_col9\" class=\"data row2 col9\" >-0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row3\" class=\"row_heading level0 row3\" >2004</th>\n",
       "      <td id=\"T_f2d76_row3_col0\" class=\"data row3 col0\" >-56,116</td>\n",
       "      <td id=\"T_f2d76_row3_col1\" class=\"data row3 col1\" >138,769</td>\n",
       "      <td id=\"T_f2d76_row3_col2\" class=\"data row3 col2\" >-41,694</td>\n",
       "      <td id=\"T_f2d76_row3_col3\" class=\"data row3 col3\" >497,591</td>\n",
       "      <td id=\"T_f2d76_row3_col4\" class=\"data row3 col4\" >203,342</td>\n",
       "      <td id=\"T_f2d76_row3_col5\" class=\"data row3 col5\" >158,105</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row3_col8\" class=\"data row3 col8\" >-0</td>\n",
       "      <td id=\"T_f2d76_row3_col9\" class=\"data row3 col9\" >-0</td>\n",
       "      <td id=\"T_f2d76_row3_col10\" class=\"data row3 col10\" >-0</td>\n",
       "      <td id=\"T_f2d76_row3_col11\" class=\"data row3 col11\" >-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row4\" class=\"row_heading level0 row4\" >2005</th>\n",
       "      <td id=\"T_f2d76_row4_col0\" class=\"data row4 col0\" >106,873</td>\n",
       "      <td id=\"T_f2d76_row4_col1\" class=\"data row4 col1\" >-37,496</td>\n",
       "      <td id=\"T_f2d76_row4_col2\" class=\"data row4 col2\" >77,233</td>\n",
       "      <td id=\"T_f2d76_row4_col3\" class=\"data row4 col3\" >-91,479</td>\n",
       "      <td id=\"T_f2d76_row4_col4\" class=\"data row4 col4\" >-106,323</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row4_col8\" class=\"data row4 col8\" >-0</td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row4_col10\" class=\"data row4 col10\" >-0</td>\n",
       "      <td id=\"T_f2d76_row4_col11\" class=\"data row4 col11\" >-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row5\" class=\"row_heading level0 row5\" >2006</th>\n",
       "      <td id=\"T_f2d76_row5_col0\" class=\"data row5 col0\" >42,334</td>\n",
       "      <td id=\"T_f2d76_row5_col1\" class=\"data row5 col1\" >98,247</td>\n",
       "      <td id=\"T_f2d76_row5_col2\" class=\"data row5 col2\" >22,812</td>\n",
       "      <td id=\"T_f2d76_row5_col3\" class=\"data row5 col3\" >-159,204</td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row5_col5\" class=\"data row5 col5\" >-0</td>\n",
       "      <td id=\"T_f2d76_row5_col6\" class=\"data row5 col6\" >-0</td>\n",
       "      <td id=\"T_f2d76_row5_col7\" class=\"data row5 col7\" >-0</td>\n",
       "      <td id=\"T_f2d76_row5_col8\" class=\"data row5 col8\" >-0</td>\n",
       "      <td id=\"T_f2d76_row5_col9\" class=\"data row5 col9\" >-0</td>\n",
       "      <td id=\"T_f2d76_row5_col10\" class=\"data row5 col10\" >-0</td>\n",
       "      <td id=\"T_f2d76_row5_col11\" class=\"data row5 col11\" >-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row6\" class=\"row_heading level0 row6\" >2007</th>\n",
       "      <td id=\"T_f2d76_row6_col0\" class=\"data row6 col0\" >48,990</td>\n",
       "      <td id=\"T_f2d76_row6_col1\" class=\"data row6 col1\" >-79,302</td>\n",
       "      <td id=\"T_f2d76_row6_col2\" class=\"data row6 col2\" >29,920</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row6_col6\" class=\"data row6 col6\" >-0</td>\n",
       "      <td id=\"T_f2d76_row6_col7\" class=\"data row6 col7\" >-0</td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row6_col9\" class=\"data row6 col9\" >-0</td>\n",
       "      <td id=\"T_f2d76_row6_col10\" class=\"data row6 col10\" >-0</td>\n",
       "      <td id=\"T_f2d76_row6_col11\" class=\"data row6 col11\" >-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row7\" class=\"row_heading level0 row7\" >2008</th>\n",
       "      <td id=\"T_f2d76_row7_col0\" class=\"data row7 col0\" >-110,168</td>\n",
       "      <td id=\"T_f2d76_row7_col1\" class=\"data row7 col1\" >-218,227</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row7_col6\" class=\"data row7 col6\" >-0</td>\n",
       "      <td id=\"T_f2d76_row7_col7\" class=\"data row7 col7\" >-0</td>\n",
       "      <td id=\"T_f2d76_row7_col8\" class=\"data row7 col8\" >-0</td>\n",
       "      <td id=\"T_f2d76_row7_col9\" class=\"data row7 col9\" >-0</td>\n",
       "      <td id=\"T_f2d76_row7_col10\" class=\"data row7 col10\" >-0</td>\n",
       "      <td id=\"T_f2d76_row7_col11\" class=\"data row7 col11\" >-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row8\" class=\"row_heading level0 row8\" >2009</th>\n",
       "      <td id=\"T_f2d76_row8_col0\" class=\"data row8 col0\" >-13,875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row8_col3\" class=\"data row8 col3\" >0</td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row8_col5\" class=\"data row8 col5\" >-0</td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row8_col7\" class=\"data row8 col7\" >-0</td>\n",
       "      <td id=\"T_f2d76_row8_col8\" class=\"data row8 col8\" >-0</td>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row8_col10\" class=\"data row8 col10\" >-0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f2d76_level0_row9\" class=\"row_heading level0 row9\" >2010</th>\n",
       "      <td></td>\n",
       "      <td id=\"T_f2d76_row9_col1\" class=\"data row9 col1\" >-0</td>\n",
       "      <td id=\"T_f2d76_row9_col2\" class=\"data row9 col2\" >-0</td>\n",
       "      <td id=\"T_f2d76_row9_col3\" class=\"data row9 col3\" >-0</td>\n",
       "      <td id=\"T_f2d76_row9_col4\" class=\"data row9 col4\" >-0</td>\n",
       "      <td id=\"T_f2d76_row9_col5\" class=\"data row9 col5\" >0</td>\n",
       "      <td id=\"T_f2d76_row9_col6\" class=\"data row9 col6\" >-0</td>\n",
       "      <td id=\"T_f2d76_row9_col7\" class=\"data row9 col7\" >0</td>\n",
       "      <td id=\"T_f2d76_row9_col8\" class=\"data row9 col8\" >0</td>\n",
       "      <td id=\"T_f2d76_row9_col9\" class=\"data row9 col9\" >0</td>\n",
       "      <td id=\"T_f2d76_row9_col10\" class=\"data row9 col10\" >-0</td>\n",
       "      <td id=\"T_f2d76_row9_col11\" class=\"data row9 col11\" >0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(genins_model.full_triangle_ - genins_model.full_expectation_).heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting comfortable with manipulating `Triangle`s will greatly improve our ability to extract value out of the `chainladder` package. Here is another way of getting the same answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "      <th>36</th>\n",
       "      <th>48</th>\n",
       "      <th>60</th>\n",
       "      <th>72</th>\n",
       "      <th>84</th>\n",
       "      <th>96</th>\n",
       "      <th>108</th>\n",
       "      <th>120</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>87,787</td>\n",
       "      <td>182,110</td>\n",
       "      <td>88,158</td>\n",
       "      <td>-182,340</td>\n",
       "      <td>-72,364</td>\n",
       "      <td>209,463</td>\n",
       "      <td>87,462</td>\n",
       "      <td>45,377</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>-24,007</td>\n",
       "      <td>-76,765</td>\n",
       "      <td>-124,048</td>\n",
       "      <td>9,899</td>\n",
       "      <td>-125,615</td>\n",
       "      <td>-212,094</td>\n",
       "      <td>-58,022</td>\n",
       "      <td>-45,377</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>-81,818</td>\n",
       "      <td>-7,335</td>\n",
       "      <td>-52,380</td>\n",
       "      <td>-74,468</td>\n",
       "      <td>100,960</td>\n",
       "      <td>-155,475</td>\n",
       "      <td>-29,439</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>-56,116</td>\n",
       "      <td>138,769</td>\n",
       "      <td>-41,694</td>\n",
       "      <td>497,591</td>\n",
       "      <td>203,342</td>\n",
       "      <td>158,105</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>106,873</td>\n",
       "      <td>-37,496</td>\n",
       "      <td>77,233</td>\n",
       "      <td>-91,479</td>\n",
       "      <td>-106,323</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>42,334</td>\n",
       "      <td>98,247</td>\n",
       "      <td>22,812</td>\n",
       "      <td>-159,204</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>48,990</td>\n",
       "      <td>-79,302</td>\n",
       "      <td>29,920</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-110,168</td>\n",
       "      <td>-218,227</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-13,875</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "                12             24             36             48             60             72            84            96            108  120\n",
       "2001   87786.584355  182109.854207   88157.704861 -182340.046069  -72364.206180  209463.211490  87461.697305  45377.021916  4.656613e-10  NaN\n",
       "2002  -24007.006253  -76765.409669 -124047.730972    9899.295819 -125615.456548 -212093.852125 -58022.270396 -45377.021916           NaN  NaN\n",
       "2003  -81818.315504   -7335.184258  -52380.464273  -74467.773015  100960.477986 -155474.528980 -29439.426909           NaN           NaN  NaN\n",
       "2004  -56115.956096  138768.957566  -41694.368640  497591.418491  203341.953249  158105.169615           NaN           NaN           NaN  NaN\n",
       "2005  106872.747755  -37496.484673   77232.720516  -91478.875281 -106322.768507            NaN           NaN           NaN           NaN  NaN\n",
       "2006   42333.899273   98247.032955   22811.664568 -159204.019945            NaN            NaN           NaN           NaN           NaN  NaN\n",
       "2007   48990.342828  -79302.054276   29920.473940            NaN            NaN            NaN           NaN           NaN           NaN  NaN\n",
       "2008 -110167.520951 -218226.711852            NaN            NaN            NaN            NaN           NaN           NaN           NaN  NaN\n",
       "2009  -13874.775407            NaN            NaN            NaN            NaN            NaN           NaN           NaN           NaN  NaN\n",
       "2010            NaN            NaN            NaN            NaN            NaN            NaN           NaN           NaN           NaN  NaN"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = genins - genins_model.full_expectation_\n",
    "out[out.valuation <= genins.valuation_date]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you figure out how to get the expected IBNR runoff in the upcoming year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2011</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>46,608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>94,634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>375,833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>247,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>334,148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>383,287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>605,548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>1,310,258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>1,018,834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>856,804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "              2011\n",
       "2001  4.660832e+04\n",
       "2002  9.463381e+04\n",
       "2003  3.758335e+05\n",
       "2004  2.471900e+05\n",
       "2005  3.341481e+05\n",
       "2006  3.832866e+05\n",
       "2007  6.055481e+05\n",
       "2008  1.310258e+06\n",
       "2009  1.018834e+06\n",
       "2010  8.568035e+05"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_yr_ibnr = genins_model.full_triangle_.dev_to_val().cum_to_incr()\n",
    "cal_yr_ibnr[cal_yr_ibnr.valuation.year == 2011]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### The Bornhuetter-Ferguson Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BornhuetterFerguson` estimator is another deterministic method having many of the same attributes as the `Chainladder` estimator. It comes with one input assumption, the a priori (`apriori`). This is a scalar multiplier that will be applied to an exposure vector, which will produce an a priori ultimate estimate vector that we can use for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The BornhuetterFerguson method\n",
    "The `BornhuetterFerguson` estimator is another deterministic method having many of the same attributes as the `Chainladder` estimator.  It comes with one assumption, the `apriori`.  This is a scalar multiplier that is to be applied to an exposure vector to determine an apriori ultimate estimate of our model.\n",
    "\n",
    "Since the CAS Loss Reserve Database has premium, we will use it as an example.  Let's grab the paid loss and net earned premium  for the commercial auto line of business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that `apriori` is a scaler, which we need to apply it to a vector of exposures. Let's assume that the a priori is 0.75, for 75% loss ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set an apriori Loss Ratio estimate of 75%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `BornhuetterFerguson` method along with all other expected loss methods like `CapeCod` and `Benktander` (discussed later), need to take in an exposure vector. The exposure vector has to be a `Triangle` itself. Remember that the `Triangle` class supports single exposure vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BornhuetterFerguson(apriori=0.75)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_model.fit(\n",
    "    comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>626,097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>679,224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>728,363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>729,927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>767,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>833,686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>918,582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>954,377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>985,280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1,031,637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "              2261\n",
       "1988  6.260970e+05\n",
       "1989  6.792242e+05\n",
       "1990  7.283626e+05\n",
       "1991  7.299271e+05\n",
       "1992  7.676100e+05\n",
       "1993  8.336865e+05\n",
       "1994  9.185817e+05\n",
       "1995  9.543771e+05\n",
       "1996  9.852804e+05\n",
       "1997  1.031637e+06"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_model.ultimate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an `apriori` that takes on only a constant for all origins can be limiting. However, we can apply a varying vector on the exposure vector to get a varying `apriori`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BornhuetterFerguson(apriori=0.75)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_model.fit(\n",
    "    comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having an `apriori` that takes on only a constant for all origins can be limiting.  This shouldn't stop the practitioner from exploiting the fact that the `apriori` can be embedded directly in the exposure vector itself allowing full cusomization of the `apriori`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = cl.BornhuetterFerguson(apriori=0.75).fit(\n",
    "    comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "\n",
    "b2 = cl.BornhuetterFerguson(apriori=1.00).fit(\n",
    "    comauto[\"CumPaidLoss\"],\n",
    "    sample_weight=0.75 * comauto[\"EarnedPremNet\"].latest_diagonal,\n",
    ")\n",
    "\n",
    "b1.ultimate_ == b2.ultimate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we need to create a new colume, such as `AdjEarnedPrmNet` with varying implied loss ratios. It is recommend that we perform any data modification in `pandas` instead of `Triangle` forms.\n",
    "\n",
    "Let's perform the estimate using `Chainladder` and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Period('1988', 'A-DEC'), Period('1989', 'A-DEC'),\n",
       "       Period('1990', 'A-DEC'), Period('1991', 'A-DEC'),\n",
       "       Period('1992', 'A-DEC'), Period('1993', 'A-DEC'),\n",
       "       Period('1994', 'A-DEC'), Period('1995', 'A-DEC'),\n",
       "       Period('1996', 'A-DEC'), Period('1997', 'A-DEC')], dtype=object)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf_ult.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-316f45db1892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcl_ult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2261\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"CL\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lower right\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbf_ult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/cl_dev/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mxlabel\u001b[0;34m(xlabel, fontdict, labelpad, loc, **kwargs)\u001b[0m\n\u001b[1;32m   3294\u001b[0m     return gca().set_xlabel(\n\u001b[1;32m   3295\u001b[0m         \u001b[0mxlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabelpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3296\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   3297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cl_dev/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mset_xlabel\u001b[0;34m(self, xlabel, fontdict, labelpad, loc, **kwargs)\u001b[0m\n\u001b[1;32m   3336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3337\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhorizontalalignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'right'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3338\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3340\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvert_xaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cl_dev/lib/python3.7/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mset_label_text\u001b[0;34m(self, label, fontdict, **kwargs)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \"\"\"\n\u001b[1;32m   1556\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misDefault_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfontdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfontdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/cl_dev/lib/python3.7/site-packages/matplotlib/text.py\u001b[0m in \u001b[0;36mset_text\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cl_model = cl.Chainladder().fit(comauto[\"CumPaidLoss\"])\n",
    "cl_ult = cl_model.ultimate_.to_frame()\n",
    "bf_ult = bf_model.ultimate_.to_frame()\n",
    "\n",
    "plt.plot(bf_ult[\"2261\"].to_numpy(), label=\"BF\")\n",
    "plt.plot(cl_ult[\"2261\"].to_numpy(), label=\"CL\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel(bf_ult.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Benktander Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Benktander` method is similar to the `BornhuetterFerguson` method, but allows for the specification of one additional assumption, `n_iters`, the number of iterations to recalculate the ultimates. The Benktander method generalizes both the BornhuetterFerguson and the Chainladder estimator through this assumption.\n",
    "\n",
    "- When `n_iters = 1`, the result is equivalent to the `BornhuetterFerguson` estimator.\n",
    "- where `n_iters` is sufficiently large, the result converges to the `Chainladder` estimator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_model = cl.Benktander(apriori=0.75, n_iters=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the `Benktander` method looks identical to the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Benktander(apriori=0.75, n_iters=2)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bk_model.fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fbb61a523d0>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bk_ult = bk_model.ultimate_.to_frame()\n",
    "plt.plot(bf_ult[\"2261\"].to_numpy(), label=\"BF\")\n",
    "plt.plot(cl_ult[\"2261\"].to_numpy(), label=\"CL\")\n",
    "plt.plot(bk_ult[\"2261\"].to_numpy(), label=\"BK\")\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Cape Cod Method\n",
    "The `CapeCod` method is similar to the `BornhuetterFerguson` method, except its `apriori` is computed from the `Triangle` itself. Instead of specifying an `apriori`, `decay` and `trend` need to be specified.  \n",
    "\n",
    " - `decay` is the rate that gives weights to earlier origin periods.\n",
    " - `trend` is the trend rate along the origin axis to reflect systematic inflationary impacts on the a priori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_model = cl.CapeCod(decay=1, trend=0).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we `fit` a `CapeCod` method, we can see the `apriori` it computes with the given `decay` and `trend` assumptions. Since it is an array of estimated parameters, this `CapeCod` attribute is called the `apriori_`, with a trailing underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          2261\n",
       "1988  0.685686\n",
       "1989  0.685686\n",
       "1990  0.685686\n",
       "1991  0.685686\n",
       "1992  0.685686\n",
       "1993  0.685686\n",
       "1994  0.685686\n",
       "1995  0.685686\n",
       "1996  0.685686\n",
       "1997  0.685686"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_model.apriori_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a `decay=1`, each `origin` period gets the same `apriori_`.  Let's verify that this `apriori_` makes sense.  It should be the latest incurred losses over the 'used up premium' where 'used up premium' is the premium vector / CDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6856862224535671"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_diagonal = comauto[\"CumPaidLoss\"].latest_diagonal\n",
    "\n",
    "cdf_as_origin_vector = (\n",
    "    cl.Chainladder().fit(comauto[\"CumPaidLoss\"]).ultimate_\n",
    "    / comauto[\"CumPaidLoss\"].latest_diagonal\n",
    ")\n",
    "\n",
    "used_up_premium = comauto[\"EarnedPremNet\"].latest_diagonal / cdf_as_origin_vector\n",
    "\n",
    "apriori_check = latest_diagonal.sum() / used_up_premium.sum()\n",
    "apriori_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a `decay=0`, the `apriori_` for each `origin` period stands on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2261</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.6853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.6478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.6518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.6815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          2261\n",
       "1988  0.685281\n",
       "1989  0.704094\n",
       "1990  0.690279\n",
       "1991  0.647802\n",
       "1992  0.651835\n",
       "1993  0.681518\n",
       "1994  0.692516\n",
       "1995  0.700403\n",
       "1996  0.703893\n",
       "1997  0.761919"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_model = cl.CapeCod(decay=0, trend=0).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "cc_model.apriori_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same on our manually calculated `apriori_` yields the same result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1997</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>0.6853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.7041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>0.6903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>0.6478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>0.6518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.6815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.6925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.7004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.7039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "          1997\n",
       "1988  0.685281\n",
       "1989  0.704094\n",
       "1990  0.690279\n",
       "1991  0.647802\n",
       "1992  0.651835\n",
       "1993  0.681518\n",
       "1994  0.692516\n",
       "1995  0.700403\n",
       "1996  0.703893\n",
       "1997  0.761919"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_diagonal / used_up_premium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine our `apriori_` for whether it exhibits any trending over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Apriori by Accident Year'}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_model.apriori_.plot(title=\"Apriori by Accident Year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much trend, but lets judgementally flatten it by modifying our `trend` assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Original vs Trended Apriori'}>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trended_cc_model = cl.CapeCod(decay=0, trend=0.01).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "\n",
    "cc_model.apriori_.to_frame().merge(\n",
    "    trended_cc_model.apriori_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"_original\", \"_trended\"),\n",
    ").plot(title=\"Original vs Trended Apriori\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding `trend` to the `CapeCod` method is intended to adjust `apriori_`s to a common level.  Once at a common level, the `apriori_` can be estimated from multiple `origin` periods using the `decay` factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Original vs Trended and Blended Apriori'}>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trended_cc_model = cl.CapeCod(decay=0.75, trend=0.01).fit(\n",
    "    X=comauto[\"CumPaidLoss\"], sample_weight=comauto[\"EarnedPremNet\"].latest_diagonal\n",
    ")\n",
    "\n",
    "cc_model.apriori_.to_frame().merge(\n",
    "    trended_cc_model.apriori_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"_untrended\", \"_trended\"),\n",
    ").plot(title=\"Original vs Trended and Blended Apriori\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once estimated, it is necessary to detrend our `apriori_`s back to their untrended levels and these are contained in `detrended_apriori_`. It is the `detrended_apriori_` that gets used in the calculation of `ultimate_` losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Original vs Blended Apriori'}>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc_model.apriori_.to_frame().merge(\n",
    "    trended_cc_model.detrended_apriori_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"_original\", \"_smoothed\"),\n",
    ").plot(title=\"Original vs Blended Apriori\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `detrended_apriori_` is a much smoother estimate of the initial expected `ultimate_`.  With the `detrended_apriori_` in hand, the `CapeCod` method estimator behaves exactly like our the `BornhuetterFerguson` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BF vs CC Difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "bf = cl.BornhuetterFerguson().fit(\n",
    "    X=comauto[\"CumPaidLoss\"],\n",
    "    sample_weight=trended_cc_model.detrended_apriori_\n",
    "    * comauto[\"EarnedPremNet\"].latest_diagonal,\n",
    ")\n",
    "print(\"BF vs CC Difference: \", bf.ultimate_.sum() - trended_cc_model.ultimate_.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now compare the `CapeCod ultimate_` to the basic `Chainladder` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'CC vs CL'}>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trended_cc_model.ultimate_.to_frame().merge(\n",
    "    cl_model.ultimate_.to_frame(),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"CC\", \"CL\"),\n",
    ").plot(title=\"CC vs CL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "* All the deterministic estimators have `ultimate_`, `ibnr_`, `full_expecation_` and `full_triangle_` attributes that are themselves `Triangle`s.  These can be manipulated in a variety of ways to gain additional insights from your model.<br>\n",
    "* The expected loss methods take in an exposure vector which itself is a `Triangle` through the `sample_weight` argument of the `fit` method.<br>\n",
    "* The `CapeCod` method has the additional attributes `apriori_` and `detrended_apriori_` to accomodate the selection of its `trend` and `decay` assumptions.\n",
    "\n",
    "Finally, these esimators work very well with the transformers discussed in previous tutorials.  Let's go to town demonstating the compositional nature of these estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'Accident Year'), Text(0, 0.5, 'Ultimates')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wkcomp = (\n",
    "    cl.load_sample(\"clrd\")\n",
    "    .groupby(\"LOB\")\n",
    "    .sum()\n",
    "    .loc[\"wkcomp\"][[\"CumPaidLoss\", \"EarnedPremNet\"]]\n",
    ")\n",
    "\n",
    "patterns = cl.Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"dev\",\n",
    "            cl.Development(\n",
    "                average=[\"simple\"] * 5 + [\"volume\"] * 4,\n",
    "                n_periods=7,\n",
    "                drop_valuation=\"1995\",\n",
    "            ),\n",
    "        ),\n",
    "        (\"tail\", cl.TailCurve(curve=\"inverse_power\", extrap_periods=80)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "cc = cl.CapeCod(decay=0.8, trend=0.02).fit(\n",
    "    X=patterns.fit_transform(wkcomp[\"CumPaidLoss\"]),\n",
    "    sample_weight=wkcomp[\"EarnedPremNet\"].latest_diagonal,\n",
    ")\n",
    "\n",
    "cc.ultimate_.plot(\n",
    "    kind=\"bar\",\n",
    "    color=\"hotpink\",\n",
    "    alpha=0.7,\n",
    "    legend=False,\n",
    "    title=\"Workers Compensation Industry Model\\n\" + \"Cape Cod with InversePower Tail\",\n",
    ").set(xlabel=\"Accident Year\", ylabel=\"Ultimates\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
