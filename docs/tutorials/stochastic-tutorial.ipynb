{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Stochastic Methods\n",
    "### Getting Started\n",
    "This tutorial focuses on using stochastic methods to estimate ultimates. \n",
    "\n",
    "Note that a lot of the examples shown here might not be applicable in a real world scenario, and is only meant to demonstrate some of the functionalities included in the package. The user should always exercise their best actuarial judgement, and follow any applicable laws, the Code of Professional Conduct, and applicable Actuarial Standards of Practice.\n",
    "\n",
    "Be sure to make sure your packages are updated. For more info on how to update your pakages, visit [Keeping Packages Updated](https://chainladder-python.readthedocs.io/en/latest/install.html#keeping-packages-updated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.3.2\n",
      "numpy: 1.20.3\n",
      "chainladder: 0.8.8\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import chainladder as cl\n",
    "# import seaborn as sns\n",
    "# sns.set_style('whitegrid')\n",
    "# %matplotlib inline\n",
    "# print('chainladder:' + cl.__version__)\n",
    "# print('pandas:' + pd.__version__)\n",
    "\n",
    "# Black linter, optional\n",
    "%load_ext lab_black\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chainladder as cl\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"pandas: \" + pd.__version__)\n",
    "print(\"numpy: \" + np.__version__)\n",
    "print(\"chainladder: \" + cl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to MackChainladder\n",
    "\n",
    "Like the basic `Chainladder` method, the `MackChainladder` is entirely specified by its selected development pattern. In fact, it is the basic `Chainladder`, but with extra features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clrd = (\n",
    "    cl.load_sample(\"clrd\")\n",
    "    .groupby(\"LOB\")\n",
    "    .sum()\n",
    "    .loc[\"wkcomp\", [\"CumPaidLoss\", \"EarnedPremNet\"]]\n",
    ")\n",
    "\n",
    "cl.Chainladder().fit(clrd[\"CumPaidLoss\"]).ultimate_ == cl.MackChainladder().fit(\n",
    "    clrd[\"CumPaidLoss\"]\n",
    ").ultimate_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Mack's Chainladder model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mack = cl.MackChainladder().fit(clrd[\"CumPaidLoss\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MackChainladder has the following additional fitted features that the deterministic `Chainladder` does not:\n",
    "\n",
    "- `full_std_err_`:  The full standard error\n",
    "- `total_process_risk_`: The total process error\n",
    "- `total_parameter_risk_`: The total parameter error\n",
    "- `mack_std_err_`: The total prediction error by origin period\n",
    "- `total_mack_std_err_`: The total prediction error across all origin periods\n",
    "\n",
    "Notice these are all measures of uncertainty, but where can they be applied? Let's start by examining the `link_ratios` underlying the triangle between age 12 and 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>285,804</td>\n",
       "      <td>638,532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>307,720</td>\n",
       "      <td>684,140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>320,124</td>\n",
       "      <td>757,479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>347,417</td>\n",
       "      <td>793,749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>342,982</td>\n",
       "      <td>781,402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>342,385</td>\n",
       "      <td>743,433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>351,060</td>\n",
       "      <td>750,392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>343,841</td>\n",
       "      <td>768,575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>381,484</td>\n",
       "      <td>736,040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "            12        24\n",
       "1988  285804.0  638532.0\n",
       "1989  307720.0  684140.0\n",
       "1990  320124.0  757479.0\n",
       "1991  347417.0  793749.0\n",
       "1992  342982.0  781402.0\n",
       "1993  342385.0  743433.0\n",
       "1994  351060.0  750392.0\n",
       "1995  343841.0  768575.0\n",
       "1996  381484.0  736040.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clrd_first_lags = clrd[clrd.development <= 24][clrd.origin < \"1997\"][\"CumPaidLoss\"]\n",
    "clrd_first_lags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple average link-ratio can be directly computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2066789527531494"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clrd_first_lags.link_ratio.to_frame().mean()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also verify that the result is the same as the `Development` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2066789527531494"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl.Development(average=\"simple\").fit(clrd[\"CumPaidLoss\"]).ldf_.to_frame().values[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Linear Regression Framework\n",
    "\n",
    "Mack noted that the estimate for the LDF is really just a linear regression fit. In the case of using the `simple` average, it is a weighted regression where the weight is set to $\\left (\\frac{1}{X}  \\right )^{2}$.\n",
    "\n",
    "Take a look at the fitted coefficient in the next cell and verify that it ties to the direct calculations above.\n",
    "With the regression framework in hand, we get much more information about our LDF estimate than just the coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kenneth.hsu/opt/anaconda3/envs/cl_dev/lib/python3.7/site-packages/scipy/stats/stats.py:1604: UserWarning: kurtosistest only valid for n>=20 ... continuing anyway, n=9\n",
      "  \"anyway, n=%i\" % int(n))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>WLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   2887.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 01 Sep 2021</td> <th>  Prob (F-statistic):</th>          <td>1.60e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:43:27</td>     <th>  Log-Likelihood:    </th>          <td> -107.89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>     9</td>      <th>  AIC:               </th>          <td>   217.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     8</td>      <th>  BIC:               </th>          <td>   218.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    2.2067</td> <td>    0.041</td> <td>   53.735</td> <td> 0.000</td> <td>    2.112</td> <td>    2.301</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 7.448</td> <th>  Durbin-Watson:     </th> <td>   1.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.024</td> <th>  Jarque-Bera (JB):  </th> <td>   2.533</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-1.187</td> <th>  Prob(JB):          </th> <td>   0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.058</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 WLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.997\n",
       "Model:                            WLS   Adj. R-squared (uncentered):              0.997\n",
       "Method:                 Least Squares   F-statistic:                              2887.\n",
       "Date:                Wed, 01 Sep 2021   Prob (F-statistic):                    1.60e-11\n",
       "Time:                        22:43:27   Log-Likelihood:                         -107.89\n",
       "No. Observations:                   9   AIC:                                      217.8\n",
       "Df Residuals:                       8   BIC:                                      218.0\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             2.2067      0.041     53.735      0.000       2.112       2.301\n",
       "==============================================================================\n",
       "Omnibus:                        7.448   Durbin-Watson:                   1.177\n",
       "Prob(Omnibus):                  0.024   Jarque-Bera (JB):                2.533\n",
       "Skew:                          -1.187   Prob(JB):                        0.282\n",
       "Kurtosis:                       4.058   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = clrd_first_lags.to_frame().values[:, 1]\n",
    "X = clrd_first_lags.to_frame().values[:, 0]\n",
    "\n",
    "model = sm.WLS(y, X, weights=(1 / X) ** 2)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By toggling the weights of our regression, we can handle the most common types of averaging used in picking loss development factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Does this work for simple?')\n",
    "print(round(cl.Development(average='simple').fit(tri_first_lags).ldf_.to_frame().values[0, 0], 8) == \\\n",
    "      round(sm.WLS(y, X, weights=(1/X)**2).fit().params[0],8))\n",
    "print('Does this work for volume-weighted average?')\n",
    "print(round(cl.Development(average='volume').fit(tri_first_lags).ldf_.to_frame().values[0, 0], 8) == \\\n",
    "      round(sm.WLS(y, X, weights=(1/X)).fit().params[0],8))\n",
    "print('Does this work for regression average?')\n",
    "print(round(cl.Development(average='regression').fit(tri_first_lags).ldf_.to_frame().values[0, 0], 8) == \\\n",
    "      round(sm.OLS(y, X).fit().params[0],8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This regression framework is what the `Development` estimator uses to set development patterns.  Although we discard the information in deterministic approaches, `Development` has two useful statistics for estimating reserve variability, both of which come from the regression framework.  The stastics are `std_err_` and `sigma_` and they are used by the `MackChainladder` estimator to determine the prediction error of our reserves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = cl.Development(average='simple').fit(tri['CumPaidLoss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.std_err_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev.sigma_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the regression framework is weighted, we can easily turn on/off any observation we want using the dropping capabilities of the `Development` estimator.  Dropping link ratios not only affects the `ldf_` and `cdf_`, but also the `std_err_` and `sigma` of the regression.\n",
    "\n",
    "Here we eliminate the 1988 valuation from our triangle, which is identical to eliminating the first observation from our 12-24 regression fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Does this work for dropping observations?')\n",
    "print(round(cl.Development(average='volume', drop_valuation='1988') \\\n",
    "              .fit(tri['CumPaidLoss']).std_err_.to_frame().values[0, 0], 8) == \\\n",
    "      round(sm.WLS(y[1:], X[1:], weights=(1/X[1:])).fit().bse[0],8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With `sigma_` and `std_err_` in hand, Mack goes on to develop recursive formulas to estimate `parameter_risk_` and `process_risk_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mack.parameter_risk_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption of Independence\n",
    "The Mack model makes a lot of assumptions about independence (i.e. covariance between random processes is 0).  This means many of the Variance estimates in the `MackChainladder` model follow the form of $Var(A+B) = Var(A)+Var(B)$.\n",
    "\n",
    "Notice the square of `mack_std_err_` is simply the sum of the sqaures of `parameter_risk_` and `process_risk_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameter risk and process risk are independent?')\n",
    "print(round(mack.mack_std_err_**2, 4) == round(mack.parameter_risk_**2 + mack.process_risk_**2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This independence assumption applies to variance of each origin period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total Parameter and process risk across origin periods is independent?')\n",
    "print(round(mack.total_process_risk_**2, 4) == round((mack.process_risk_**2).sum('origin'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independence is also assumed to apply to the overall standard error of reserves, `total_mack_std_err_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mack.total_process_risk_**2 + mack.total_parameter_risk_**2).to_frame().values[0, -1] == \\\n",
    "(mack.total_mack_std_err_**2).values[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This over-reliance on independence is one of the weaknesses of the `MackChainladder` method. Nevertheless, if the data align with this assumption, then `total_mack_std_err_` is a reasonable esimator of reserve variability.\n",
    "\n",
    "### Mack Reserve Variability\n",
    "The `mack_std_err_` at ultimate is the reserve variability for each `origin` period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mack.mack_std_err_[mack.mack_std_err_.development==mack.mack_std_err_.development.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are probably easier to see in the `summary_` of the `MackChainladder` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mack.summary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = mack.summary_.to_frame()\n",
    "g = plot_data[['Latest', 'IBNR']] \\\n",
    "    .plot(kind='bar', stacked=True,\n",
    "          yerr=pd.DataFrame({'latest': plot_data['Mack Std Err']*0,\n",
    "                             'IBNR': plot_data['Mack Std Err']}),\n",
    "          ylim=(0, None), title='Mack Chainladder Ultimate')\n",
    "g.set_xlabel('Accident Year')\n",
    "g.set_ylabel('Loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = pd.Series(np.random.normal(mack.ibnr_.sum(),\n",
    "                           mack.total_mack_std_err_.values[0, 0], size=10000))\n",
    "dist.plot(\n",
    "    kind='hist', bins=50,\n",
    "    title=\"Normally distributed IBNR estimate with a mean of \" + '{:,}'.format(round(mack.ibnr_.sum(),0))[:-2]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ODP Bootstrap Model\n",
    "\n",
    "The `MackChainladder` focused on a regression framework for determining the variability of reserve estimates.  An alternative approach is to use statistical bootstrapping or sampling from a triangle with replacement to simulate new triangles.\n",
    "\n",
    "Bootstrapping imposes less model constraints than the `MackChainladder` which allows for greater applicability in different scenarios.  Sampling new triangles can be accomplished through the `BootstrapODPSample` estimator.  This estimator will take a single triangle and simulate new ones from it.\n",
    "\n",
    "Notice how easy it is to simulate 10,000 new triangles from an existing triangle by accessing the `resampled_triangles_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = cl.BootstrapODPSample(n_sims=10000).fit(tri['CumPaidLoss']).resampled_triangles_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could use `BootstrapODPSample` to transform our triangle into a resampled set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = cl.BootstrapODPSample(n_sims=10000).fit_transform(tri['CumPaidLoss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notion of the ODP Bootstrap is that as our simulations approach infinity, we should expect our mean simulation to converge on the basic `Chainladder` estimate of of reserves.\n",
    "\n",
    "Let's apply the basic chainladder to our original triangle and also to our simulated triangles to see whether this holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = round(1 - cl.Chainladder().fit(samples).ibnr_.sum('origin').mean() / \\\n",
    "                       cl.Chainladder().fit(tri['CumPaidLoss']).ibnr_.sum())\n",
    "print(\"Percentage difference in estimate using original triangle and BootstrapODPSample is \" +str(difference))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using deterministic methods with Bootstrap samples\n",
    "Our `samples` is just another triangle object with all the functionality of a regular triangle.  This means we can apply any functionality we want to our `samples` including any deterministic methods we learned about previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = cl.Pipeline([\n",
    "    ('dev', cl.Development(average='simple')),\n",
    "    ('tail', cl.TailConstant(1.05))])\n",
    "pipe.fit(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now instead of a single `cdf_` vector, we have 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.named_steps.dev.cdf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to look at the varibility of any fitted property used in our prior tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_dev = cl.Development(average='simple').fit(tri['CumPaidLoss'])\n",
    "resampled_ldf = pipe.named_steps.dev.ldf_\n",
    "print(\"12-24 LDF of original Triangle: \" + str(round(orig_dev.ldf_.values[0,0,0,0],4)))\n",
    "pd.Series(resampled_ldf.values[:, 0, 0, 0]).plot(\n",
    "    kind='hist', bins=100,\n",
    "    title='Age 12-14 LDF distribution using Bootstrap');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison between Bootstrap and Mack\n",
    "We should even be able to approximate some of the Mack parameters calculated using the regression framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mack_vs_bs = resampled_ldf.std('index').to_frame().append(\n",
    "    orig_dev.std_err_.to_frame()).T\n",
    "mack_vs_bs.columns = ['Mack', 'Bootstrap']\n",
    "mack_vs_bs.plot(kind='bar', title='Mack Regression Framework LDF Std Err\\nvs\\nBootstrap Simulated LDF Std Err');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the `MackChainladder` produces statistics about the mean and variance of reserve estimates, those have to be fit to a distribution using MLE, MoM, etc to see the range of outcomes of reserves.  With `BootstrapODPSample` based fits, we can use the empirical distribution directly if we choose to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibnr = cl.Chainladder().fit(samples).ibnr_.sum('origin')\n",
    "ibnr_99 = ibnr.quantile(q=0.99)\n",
    "print(\"99%-ile of reserve estimate is \" +'{:0,}'.format(round(ibnr_99,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the `MackChainladder` reserve distribution compares to the `BootstrapODPSample` reserve distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = ibnr.plot(kind='hist', bins=50, alpha=0.7, color='green').plot()\n",
    "dist.plot(kind='hist', bins=50, alpha=0.4, color='blue', title='Mack vs Bootstrap Variability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected loss methods with Bootstrap\n",
    "\n",
    "So far, we've only applied the multiplicative methods (i.e. basic chainladder) in a stochastic context.  It is possible to use an expected loss method like the `BornhuetterFerguson`. \n",
    "\n",
    "To do this, we will need an exposure vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tri['EarnedPremNet'].latest_diagonal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing an `apriori_sigma` to the `BornhuetterFerguson` estimator tells it to consider the apriori selection itself as a random variable.  Fitting a stochastic `BornhuetterFerguson` looks very much like the determinsitic version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chainladder as cl\n",
    "import numpy as np\n",
    "clrd = cl.load_sample('clrd')\n",
    "np.prod(clrd, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.tan(cl.load_sample('raa')).T.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our knowledge of `Triangle` manipulation to grab most things we would want out of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab completed triangle replacing simulated known data with actual known data\n",
    "full_triangle = bf.full_triangle_ - bf.X_ + tri['CumPaidLoss']\n",
    "# Limiting to the current year for plotting\n",
    "current_year = full_triangle[full_triangle.origin==full_triangle.origin.max()].to_frame().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, plotting the expected development of our full triangle over time from the Bootstrap `BornhuetterFerguson` model fans out to greater uncertainty the farther we get from our valuation date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "current_year.iloc[:, :200].reset_index(drop=True).plot(\n",
    "    color='green', legend=False, alpha=0.1,\n",
    "    title='Current Accident Year Expected Development Distribution', grid=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap\n",
    "- The Mack method approaches stochastic reserving from a regression point of view<br>\n",
    "- Bootstrap methods approach stochastic reserving from a simulation point of view<br>\n",
    "- Where they assumptions of each model are not violated, they produce resonably consistent estimates of reserve variability<br>\n",
    "- Mack does impose more assumptions (i.e. constraints) on the reserve estimate making the Bootstrap approach more suitable in a broader set of applciations<br>\n",
    "- Both methods converge to their corresponding deterministic point estimates<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
