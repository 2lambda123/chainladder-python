{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Triangles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "Welcome! We drafted these tutorials to help you get familiar with some of the common functionalities that most actuaries can use in their day-to-day responsibilities. The package also comes with pre-installed datasets that you can play with, which are also used in the tutorials here.\n",
    "\n",
    "The tutorials assume that you have the basic understanding of commonly used actuarial terms, and can independently perform an actuarial analysis in another tool, such as Microsoft Excel or another actuarial software.Â Furthermore, it is assumed that you already have some familiarity with Python, and that you have the basic knowledge and experience in using some common packages that are popular in the Python community, such as `pandas` and `numpy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial is linted using [black](https://github.com/psf/black) via [nb_black](https://github.com/dnanhkhoa/nb_black). This step is optional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All tutorials and exercises rely on chainladder v0.8.5 and later. It is highly recomended that you keep your packages up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 1.3.1\n",
      "numpy: 1.21.1\n",
      "chainladder: 0.8.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chainladder as cl\n",
    "import os\n",
    "\n",
    "print(\"pandas: \" + pd.__version__)\n",
    "print(\"numpy: \" + np.__version__)\n",
    "print(\"chainladder: \" + cl.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be plotting for quite a bit, here's a magic function in IPython, which sets the backend of matplotlib to the 'inline' backend. With this backend, the output of plotting commands is displayed inline within frontends like the Jupyter notebook, directly below the code cell that produced it. The resulting plots will then also be stored in the notebook document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with a Triangle\n",
    "Let's begin by looking at an unprocessed triangle data and load it into a `pandas.DataFrame`. We'll use the data `raa`, which is available from the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>development</th>\n",
       "      <th>origin</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1981</td>\n",
       "      <td>1981</td>\n",
       "      <td>5012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1982</td>\n",
       "      <td>1982</td>\n",
       "      <td>106.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1983</td>\n",
       "      <td>1983</td>\n",
       "      <td>3410.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984</td>\n",
       "      <td>1984</td>\n",
       "      <td>5655.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>1985</td>\n",
       "      <td>1092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1986</td>\n",
       "      <td>1986</td>\n",
       "      <td>1513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1987</td>\n",
       "      <td>1987</td>\n",
       "      <td>557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1988</td>\n",
       "      <td>1988</td>\n",
       "      <td>1351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1989</td>\n",
       "      <td>1989</td>\n",
       "      <td>3133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1990</td>\n",
       "      <td>1990</td>\n",
       "      <td>2063.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1982</td>\n",
       "      <td>1981</td>\n",
       "      <td>8269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1983</td>\n",
       "      <td>1982</td>\n",
       "      <td>4285.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1984</td>\n",
       "      <td>1983</td>\n",
       "      <td>8992.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1985</td>\n",
       "      <td>1984</td>\n",
       "      <td>11555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1986</td>\n",
       "      <td>1985</td>\n",
       "      <td>9565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1987</td>\n",
       "      <td>1986</td>\n",
       "      <td>6445.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1988</td>\n",
       "      <td>1987</td>\n",
       "      <td>4020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1989</td>\n",
       "      <td>1988</td>\n",
       "      <td>6947.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1990</td>\n",
       "      <td>1989</td>\n",
       "      <td>5395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1983</td>\n",
       "      <td>1981</td>\n",
       "      <td>10907.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    development  origin   values\n",
       "0          1981    1981   5012.0\n",
       "1          1982    1982    106.0\n",
       "2          1983    1983   3410.0\n",
       "3          1984    1984   5655.0\n",
       "4          1985    1985   1092.0\n",
       "5          1986    1986   1513.0\n",
       "6          1987    1987    557.0\n",
       "7          1988    1988   1351.0\n",
       "8          1989    1989   3133.0\n",
       "9          1990    1990   2063.0\n",
       "10         1982    1981   8269.0\n",
       "11         1983    1982   4285.0\n",
       "12         1984    1983   8992.0\n",
       "13         1985    1984  11555.0\n",
       "14         1986    1985   9565.0\n",
       "15         1987    1986   6445.0\n",
       "16         1988    1987   4020.0\n",
       "17         1989    1988   6947.0\n",
       "18         1990    1989   5395.0\n",
       "19         1983    1981  10907.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raa_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/casact/chainladder-python/master/chainladder/utils/data/raa.csv\"\n",
    ")\n",
    "raa_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has three columns: \n",
    "* development: or valuation time, in this case, valuation year\n",
    "* origin: or accident date, in this case, accident year\n",
    "* values: the values recorded for the specific accident date at the specific valuation time (such as incurred losses, paid losses, or claim counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A table of loss experience showing total losses for a certain period (origin) at various, regular valuation dates (development), reflect the change in amounts as claims mature and emerge. Older periods in the table will have one more entry than the next youngest period, leading to the triangle shape of the data in the table or any other measure that matures over time from an origin date. Loss triangles can be used to determine loss development for a given risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put our data into the triangle format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raa = cl.Triangle(raa_df, origin=\"origin\", development=\"development\", columns=\"values\")\n",
    "raa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also load the example data directly, using `load_sample`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raa = cl.load_sample(\"raa\")\n",
    "raa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A triangle has more properties than just what is displayed. For example we can see the underlying `link_ratio`s, which represent the multiplicative change in amounts from one development period to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raa.link_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view (and manipulate) the `latest_diagonal` of the triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raa.latest_diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raa.latest_diagonal / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The latest diagonal also corresponds to a `valuation_date`. Note that 'valuation_date' is a datetime that is at the terminal timestamp of the period (i.e. the last split second of the year)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raa.valuation_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also tell whether our triangle:\n",
    "* `is_cumulative`: returns True if the data across the development periods is cumulative, or False if it is incremental.\n",
    "* `is_ultimate`: returns True if the ultimate values are contained in the triangle.\n",
    "* `is_val_tri`: returns True if the development period is stated as a valuation data as opposed to an age, i.e. Schedule P style triangle (True) or the more commonly used triangle by development age (False).\n",
    "* `is_full`: returns True if the triangle has been \"squared\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Is triangle cumulative?\", raa.is_cumulative)\n",
    "print(\"Does triangle contain ultimate projections?\", raa.is_ultimate)\n",
    "print(\"Is this a valuation triangle?\", raa.is_val_tri)\n",
    "print('Has the triangle been \"squared\"?', raa.is_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also inspect the triangle to understand its data granularity with `origin_grain` and `development_grain`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Origin grain:\", raa.origin_grain)\n",
    "print(\"Development grain:\", raa.development_grain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package supports monthly (\"M\"), quarterly (\"Q\") and yearly (\"Y\") grains for both `origin_grain` and `development_grain`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Triangle Structure\n",
    "The triangle described so far is a two-dimensional (accident date by valuation date) structure that spans multiple cells of data. This is a useful structure for exploring individual triangles, but becomes more problematic when working with **sets** of triangles. `Pandas` does not have a triangle `dtype`, but if it did, working with sets of triangles would be much more convenient. To facilitate working with more than one triangle at a time the `chainladder.Triangle` acts like a pandas dataframe (with an index and columns) where each cell (row x col) is an individual triangle.  This structure manifests itself as a four-dimensional space. Let's take a look at another dataset `clrd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/casact/chainladder-python/master/chainladder/utils/data/clrd.csv\"\n",
    ")\n",
    "clrd_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data into the sets of triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd = cl.Triangle(\n",
    "    clrd_df,\n",
    "    origin=\"AccidentYear\",\n",
    "    development=\"DevelopmentYear\",\n",
    "    columns=[\n",
    "        \"IncurLoss\",\n",
    "        \"CumPaidLoss\",\n",
    "        \"BulkLoss\",\n",
    "        \"EarnedPremDIR\",\n",
    "        \"EarnedPremCeded\",\n",
    "        \"EarnedPremNet\",\n",
    "    ],\n",
    "    index=[\"GRNAME\", \"LOB\"],\n",
    ")\n",
    "clrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 4D strucures do not fit nicely on 2D screens, we see a summary view instead that describes the structure rather than the underlying data itself. \n",
    "\n",
    "We see 5 rows of information:\n",
    "* Valuation: the valuation date.\n",
    "* Grain: the granularity of the data, O stands for origin, and D stands for development, `OYDY` represents triangles with accident year by development year.\n",
    "* Shape: contains 4 numbers, represents the 4-D structure. This sample triangle represents a collection of 775x6 or 4,650 triangles that are themselves 10 accident years by 10 development periods.\n",
    "    * 775: the number of segments, which is the combination of `index`, that represents the data segments. In this case, it is each of the `GRNAME` and `LOB` unique combination.\n",
    "    * 6: the number of triangles for each segment, which is also the columns `[IncurLoss, CumPaidLoss, BulkLoss, EarnedPremDIR, EarnedPremCeded, EarnedPremNet]`. They could be paid amounts, incurred amounts, reported counts, loss ratios, closure rates, excess losses, premium, etc.\n",
    "    * 10: the number of accident periods.\n",
    "    * 10: the number of valuation periods.\n",
    "* Index: the segmentation level of the triangles.\n",
    "* Columns: the value types recorded in the triangles.\n",
    "    \n",
    "To summarize the set of triangles:\n",
    "* We have a total of 775 segments, which are at the `GRNAME` and `LOB` level.\n",
    "* Each segment contains 6 triangles, which are `IncurLoss`, `CumPaidLoss`, `BulkLoss`, `EarnedPremDIR`, `EarnedPremCeded`, `EarnedPremNet`.\n",
    "* Each triangle is 10 accident years x 10 development periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `index.head()` allows us to see the first 5 segments in the set of triangles. Note that as the data is loaded, the triangle are sorted by `index`, in this case, `GRNAME` first, then by `LOB`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the hood, the data structure is a `numpy.ndarray` with the equivalent shape.  Like pandas, you can directly access the underlying numpy structure with the `values` property. By exposing the underlying `ndarray` you are free to manipulate the underlying data directly with numpy should that be an easier route to solving a problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data structure of clrd:\", type(clrd.values))\n",
    "print(\"Sum of all data values:\", np.nansum(clrd.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind though, the `chainladder.Triangle` has several methods and properties beyond the raw numpy representation and these are kept in sync by using the `chainladder.Triangle` directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas-Style Slicing\n",
    "As mentioned, the 4D structure is intended to behave like a pandas `DataFrame`.  Like pandas, we can subset a dataframe by referencing individual columns by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[[\"CumPaidLoss\", \"IncurLoss\", \"BulkLoss\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also boolean-index the rows of the Triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[clrd[\"LOB\"] == \"wkcomp\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use the typical `loc`, `iloc` functionality similar to `pandas` to access subsets of data.  These features can be chained together as much as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.loc[\"Allstate Ins Co Grp\"].iloc[-1][\"CumPaidLoss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas-Style Arithmetic\n",
    "With complete flexibility in the ability to slice subsets of triangles, we can use basic arithmetic to derive new triangles, which is commonly used as diagnostics to explore trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[\"CaseIncurLoss\"] = clrd[\"IncurLoss\"] - clrd[\"BulkLoss\"]\n",
    "clrd[\"PaidToInc\"] = clrd[\"CumPaidLoss\"] / clrd[\"CaseIncurLoss\"]\n",
    "clrd[[\"CaseIncurLoss\", \"PaidToInc\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also aggregating the values across all triangles into one triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[\"CumPaidLoss\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also construct a paid loss ratio triangle against `EarnedPremNet`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[\"CumPaidLoss\"].sum() / clrd[\"EarnedPremNet\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating all segments together is interesting, but it is often more useful to aggregate across segments using `groupby`.  For example, we may want to group the triangles by line of business and get a sum across all companies for each industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.groupby(\"LOB\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is (**6**, 8, 10, 10) because now we have 6 LOBs with 8 triangles for each LOB. We can also note that `index` is now on `[LOB]` only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clrd[\"LOB\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aggregation functions, e.g. `sum`, `mean`, `std`, `min`, `max`, etc. don't have to just apply to the `index` axis.  You can apply them to any of the four axes in the triangle object, which are `segments` (axis `0`, or the index axis), `columns` (axis `1`, the various financial fields), `origin` (axis `2`, across triangle rows), and `development` period (axis `3`, across triangle columns). You can also use either the axis name or number. Let's try to sum all of the segments (`[GRNAME, LOB]`) and columns (`[IncurLoss, CumPaidLoss, BulkLoss, EarnedPremDIR, EarnedPremCeded, EarnedPremNet]`) using axis name and number, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.sum(axis=\"index\").sum(axis=\"segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.sum(axis=0).sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessor Methods\n",
    "`Pandas` has special \"accessor\" methods for `str` and `dt`.  These allow for the manipulation of data within each cell of data:\n",
    "\n",
    "```python\n",
    "# splits lastname from first name by a comma-delimiter\n",
    "df['Last_First'].str.split(',')\n",
    "\n",
    "# pulls the year out of each date in a dataframe column\n",
    "df['Accident Date'].dt.year \n",
    "```\n",
    "\n",
    "`chainladder` also has special \"accessor\" methods to help us manipulate the `origin`, `development` and `valuation` vectors of a triangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to extract only the latest accident period for every triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[clrd.origin == clrd.origin.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this triangle has only 1 row; however, all of the columns would exist, but only the youngest age would have values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to extract particular diagonals from our triangles using its `valuation` vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[(clrd.valuation >= \"1994\") & (clrd.valuation < \"1995\")][\"CumPaidLoss\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may even want to slice particular development periods to explore aspects of our data by development age. For example, we can look at the development factors between ages 24 and 36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[(clrd.development > 12) & (clrd.development <= 36)][\"CumPaidLoss\"].sum().link_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Back to Pandas\n",
    "When the shape of a `Triangle` object can be expressed as a 2D structure (i.e. two of its four axes have a length of 1) or less, you can use the `to_frame` method to convert your data into a `pandas.DataFrame`. Let's pick only one financial field, `CumPaidLoss` and only the latest diagonal, with `latest_diagonal`. We are now left with LOBs and origin period as our 2 axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.groupby(\"LOB\").sum().latest_diagonal[\"CumPaidLoss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.groupby(\"LOB\").sum().latest_diagonal[\"CumPaidLoss\"].to_frame().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also aggregate process away 3 dimensions, then use `to_frame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[clrd.origin == \"1990\"].groupby(\"LOB\").sum().latest_diagonal[\n",
    "    \"CumPaidLoss\"\n",
    "].to_frame().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "Use the `clrd` dataset for all of the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How do we create a new column named \"NetPaidLossRatio\" in the triangle using the existing columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[\"NetPaidLossRatio\"] = clrd[\"CumPaidLoss\"] / clrd[\"EarnedPremNet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What is the highest paid loss ratio for across all segments for origin 1997 at age 12?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[clrd.origin == \"1997\"][clrd.development == 12][\"NetPaidLossRatio\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How do we subset the overall triangle to just include \"Alaska Nat Ins Co\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[clrd[\"GRNAME\"] == \"Alaska Nat Ins Co\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. How do we create a triangle subset that includes all triangles for companies with names starting with the letter \"B\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd[clrd[\"GRNAME\"].str[0] == \"B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which are the top 5 companies by net premium share for in 1990?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clrd.latest_diagonal.groupby(\"GRNAME\").sum()[clrd.origin == \"1990\"][\n",
    "    \"EarnedPremNet\"\n",
    "].to_frame().sort_values(ascending=False).iloc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a Triangle With Your Own Data\n",
    "The `chainladder.Triangle`  class is designed to ingest `pandas.DataFrame` objects. However, you do not need to worry about shaping the dataframe into triangle format yourself. This happens at the time you ingest the data.\n",
    "\n",
    "Let's look at the initialization signature and its docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl.Triangle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a new dataset `prism` to construct our triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/casact/chainladder-python/master/chainladder/utils/data/prism.csv\"\n",
    ")\n",
    "prism_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must specify the `origin`, `development`, and `columns` to create a triangle object. By limiting our columns to one measure and not specifying an index, we can create a single triangle. For example, if we are only interested in the paid triangle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = cl.Triangle(\n",
    "    data=prism_df, origin=\"AccidentDate\", development=\"PaymentDate\", columns=\"Paid\"\n",
    ")\n",
    "prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the lowest (most-detailed) grain supported is the monthly grain, so the triangle above is aggregated to the OMDM level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism.origin_grain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism.development_grain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to include more columns or indices we can certainly do so. Note that as we do this, we move into the 4D arena changing the display of the overall object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = cl.Triangle(\n",
    "    data=prism_df,\n",
    "    origin=\"AccidentDate\",\n",
    "    development=\"PaymentDate\",\n",
    "    columns=[\"Paid\", \"Incurred\"],\n",
    ")\n",
    "prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` has wonderful datetime inference functionality that the `Triangle` heavily uses to infer origin and development granularity. Even still, there are occassions where date format inferences can fail. It is often better to explicitly tell the triangle the date format, and is usually good pratice to explicitly state the date format instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = cl.Triangle(\n",
    "    data=prism_df,\n",
    "    origin=\"AccidentDate\",\n",
    "    origin_format=\"%Y-%m-%d\",\n",
    "    development=\"PaymentDate\",\n",
    "    development_format=\"%Y-%m-%d\",\n",
    "    columns=[\"Paid\", \"Incurred\"],\n",
    ")\n",
    "prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up until now, we've been playing with symmetric triangles (i.e. `orgin` and `development` periods have the same grain). However, nothing precludes us from having a different grain. Often times in practice the `development` axis is more granular than the `origin` axis. All the functionality available to symmetric triangles works equally well for asymmetric triangles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_df[\"AccYr\"] = prism_df[\"AccidentDate\"].str[:4]\n",
    "\n",
    "prism = cl.Triangle(\n",
    "    data=prism_df,\n",
    "    origin=\"AccYr\",\n",
    "    origin_format=\"%Y\",\n",
    "    development=\"PaymentDate\",\n",
    "    development_format=\"%Y-%m-%d\",\n",
    "    columns=[\"Paid\", \"Incurred\"],\n",
    ")\n",
    "prism[\"Paid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While exposure triangles make sense for auditable lines such as workers' compensation lines, most other lines of business' exposures can be expressed as a 1D array (along origin period) as exposures do not develop over time. `chainladder` arithmetic requires that operations happen between a triangle and either an `int`, `float`, or another `Triangle`. To create a 1D exposure array, simply omit the `development` argument at initialization.\n",
    "\n",
    "The `prism` data does not consist of exposure data, but we can contrive one. Let's assume that the premium is thrice the incurred amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_df[\"Premium\"] = 3 * prism_df[\"Incurred\"]\n",
    "\n",
    "prism = cl.Triangle(\n",
    "    data=prism_df, origin=\"AccidentDate\", origin_format=\"%Y-%m-%d\", columns=\"Premium\"\n",
    ")\n",
    "\n",
    "prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's seperate our data by segments using `index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = cl.Triangle(\n",
    "    data=prism_df,\n",
    "    origin=\"AccidentDate\",\n",
    "    origin_format=\"%Y-%m-%d\",\n",
    "    development=\"PaymentDate\",\n",
    "    development_format=\"%Y-%m-%d\",\n",
    "    columns=[\"Paid\", \"Incurred\"],\n",
    "    index=\"Line\",\n",
    ")\n",
    "prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can futher `index` by coverages, or sublines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = cl.Triangle(\n",
    "    data=prism_df,\n",
    "    origin=\"AccidentDate\",\n",
    "    origin_format=\"%Y-%m-%d\",\n",
    "    development=\"PaymentDate\",\n",
    "    development_format=\"%Y-%m-%d\",\n",
    "    columns=[\"Paid\", \"Incurred\"],\n",
    "    index=[\"Line\", \"Type\"],\n",
    ")\n",
    "prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Methods not Available in Pandas\n",
    "Up until now, we've kept pretty close to the pandas API for triangle manipulation. However, there are data transformations commonly applied to triangles that don't have a nice `pandas` analogy.\n",
    "\n",
    "For example, we often want to convert a triangle from an incremental view into a cumulative view and vice versa. This can be accomplished with the `incr_to_cum` and `cum_to_incr` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism[\"Paid\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_cum = prism.incr_to_cum()\n",
    "prism_cum[\"Paid\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_incr = prism_cum.cum_to_incr()\n",
    "prism_incr[\"Paid\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default (and in concert with the `pandas` philosophy), the methods associated with the `Triangle` class strive for immutability. This means that the `incr_to_cum` and `cum_to_incr` methods will return new a new triangle object that must be assigned, or it is thrown away. Many of the `chainladder.Triangle` methods have an `inplace` argument, or alternatively you can just use variable reassignment to store the transformed triangle object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works\n",
    "prism.incr_to_cum(inplace=True)\n",
    "# So does this\n",
    "prism = prism.incr_to_cum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with triangles that have an `origin` axis, `development` axis, or both at a monthly or quarterly grain, the triangle can be summarized to a higher grain using the `grain` method.\n",
    "\n",
    "The grain to which you want your triangle converted, specified as \"OxDy\" where \"x\" and \"y\" can take on values of \"M\", \"Q\", or \"Y\". For example:\n",
    "* `grain(OYDY)` for Origin Year x Development Year.\n",
    "* `grain(OQDM)` for Origin Quarter x Development Month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_OYDY = prism.grain(\"OYDY\")\n",
    "prism_OYDY[\"Paid\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the type of analysis being done, it may be more convenient to look at a triangle with its `development` axis expressed as a valuation rather than an age. This is also what the Schedule Ps look like. To do this, `Triangle` has two methods for toggling between a development triangle and a valuation triangle. The methods are `dev_to_val` and its inverse `val_to_dev`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_OYDY_val = prism_OYDY.dev_to_val()\n",
    "prism_OYDY_val[\"Paid\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with real-world data, the triangles can have holes, such as missing evluation(s), or no losses in certain origin(s). In these cases, it doesn't make sense to include empty accident periods or development ages. For example, in the `prism` dataset, the \"Home\" line has its latest accidents through 2016, and have no payments in development age '12'. Sometimes, dropping the non-applicable fields is usefule with the `dropna()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_OYDY.loc[\"Home\"][\"Paid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what happens if we have no data for 2011."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_df_2011 = prism_df.copy()\n",
    "prism_df_2011.loc[\n",
    "    (prism_df_2011[\"AccidentDate\"] >= \"2011-01-01\")\n",
    "    & (prism_df_2011[\"AccidentDate\"] < \"2012-01-01\"),\n",
    "    \"Paid\",\n",
    "] = None  # Let's assume we hav no payments for losses occurred in 2011\n",
    "prism_2011 = cl.Triangle(\n",
    "    data=prism_df_2011,\n",
    "    origin=\"AccidentDate\",\n",
    "    origin_format=\"%Y-%m-%d\",\n",
    "    development=\"PaymentDate\",\n",
    "    development_format=\"%Y-%m-%d\",\n",
    "    columns=[\"Paid\", \"Incurred\"],\n",
    "    index=[\"Line\", \"Type\"],\n",
    ")\n",
    "prism_2011.incr_to_cum(inplace=True)\n",
    "prism_2011_OYDY = prism_2011.grain(\"OYDY\")\n",
    "prism_2011_OYDY.loc[\"Home\"][\"Paid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `dropna()` method will retain empty periods if they are surrounded by non-empty periods with valid data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_2011_OYDY_droppedna = prism_2011_OYDY.loc[\"Home\"].dropna()\n",
    "prism_2011_OYDY_droppedna.loc[\"Home\"][\"Paid\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commutative Properties of Triangle Methods\n",
    "Where it makes sense, which is in most cases, the methods described above are commutative and can be applied in any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Commutative?\", prism.sum().latest_diagonal == prism.latest_diagonal.sum())\n",
    "print(\"Commutative?\", prism.loc[\"Home\"].link_ratio == prism.link_ratio.loc[\"Home\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Triangle Imports and Exports\n",
    "To the extent the `Triangle` can be expressed as a `pandas.DataFrame`, you can use any of the pandas IO to send the data in and out. Note that converting to pandas is a one-way ticket with no inverse functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful function is to copy the triangle and put it in the clipboard so we can paste it elsewhere (such as Excel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_OYDY.loc[\"Home\", \"Paid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_OYDY.loc[\"Home\", \"Paid\"].to_clipboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to paste it elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you want to store the triangle elsewhere but be able to reconstitute a triangle out of it later, then you can use:\n",
    "* `Triangle.to_json` and its inverse `cl.read_json` for json format<br>\n",
    "* `Triangle.to_pickle` and its inverse `cl.read_pickle` for pickle format<br>\n",
    "\n",
    "These have the added benefit of working on multi-dimensional triangles that don't fit into a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism = cl.Triangle(\n",
    "    data=prism_df,\n",
    "    origin=\"AccidentDate\",\n",
    "    development=\"PaymentDate\",\n",
    "    columns=[\"Paid\", \"Incurred\"],\n",
    "    index=[\"Line\", \"Type\"],  # multiple indices\n",
    ").incr_to_cum()\n",
    "prism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the case incurred activity for calendar periods in 2015Q2 (March, April, and May in 2015) by \"Line\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr_by_line = prism.groupby(\"Line\").sum().cum_to_incr()[\"Incurred\"].dev_to_val()\n",
    "incr_by_line[\n",
    "    (incr_by_line.valuation >= \"2015-04-01\") & (incr_by_line.valuation < \"2015-07-01\")\n",
    "].sum(\"origin\").to_frame().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For accident year 2015, what proportion of our Paid amounts come from each \"Type\" of claims?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prism_OYDY = prism.grain(\"OYDY\")\n",
    "prism_OYDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_type = (\n",
    "    prism_OYDY.latest_diagonal[prism_OYDY.origin == \"2015\"][\"Paid\"]\n",
    "    .groupby(\"Type\")\n",
    "    .sum()\n",
    "    .to_frame()\n",
    ")\n",
    "by_type / by_type.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
